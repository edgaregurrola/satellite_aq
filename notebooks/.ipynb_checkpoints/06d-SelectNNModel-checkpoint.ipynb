{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "plt.style.use('seaborn-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315535</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>19:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>18.10</td>\n",
       "      <td>22.27</td>\n",
       "      <td>84.00</td>\n",
       "      <td>46.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>12.68</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315544</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>20:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>27.51</td>\n",
       "      <td>84.40</td>\n",
       "      <td>57.4</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315553</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>28.60</td>\n",
       "      <td>75.30</td>\n",
       "      <td>151.5</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>6.86</td>\n",
       "      <td>22.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315562</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.43</td>\n",
       "      <td>125.60</td>\n",
       "      <td>174.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.16</td>\n",
       "      <td>32.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315571</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>23:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>58.20</td>\n",
       "      <td>66.09</td>\n",
       "      <td>141.50</td>\n",
       "      <td>144.3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.39</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FECHA   HORA PARAM    AGU     ATM     CEN     LDO  \\\n",
       "4       2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04   \n",
       "13      2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27   \n",
       "22      2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00   \n",
       "31      2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65   \n",
       "40      2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70   \n",
       "...                     ...    ...   ...    ...     ...     ...     ...   \n",
       "315535  2019-12-31 19:00:00  19:00  PM10  -1.00   18.10   22.27   84.00   \n",
       "315544  2019-12-31 20:00:00  20:00  PM10  -1.00   -1.00   27.51   84.40   \n",
       "315553  2019-12-31 21:00:00  21:00  PM10  -1.00   -1.00   28.60   75.30   \n",
       "315562  2019-12-31 22:00:00  22:00  PM10  -1.00   -1.00   50.43  125.60   \n",
       "315571  2019-12-31 23:00:00  23:00  PM10  -1.00   58.20   66.09  141.50   \n",
       "\n",
       "         LPIN     MIR     OBL     SFE     TLA    VAL  \n",
       "4        -1.0   69.75  197.67  115.54  143.40  17.08  \n",
       "13       -1.0   68.99  138.09   84.24  100.46  29.15  \n",
       "22       -1.0  117.70   98.79  135.39   82.05  30.89  \n",
       "31       -1.0  160.30   97.94  117.60  114.74  38.74  \n",
       "40       -1.0  180.89  134.39  164.68  118.83  51.48  \n",
       "...       ...     ...     ...     ...     ...    ...  \n",
       "315535   46.2   -1.00   -1.00   -1.00   12.68  16.20  \n",
       "315544   57.4   -1.00   -1.00   -1.00   50.31  14.00  \n",
       "315553  151.5   -1.00   -1.00   -1.00    6.86  22.90  \n",
       "315562  174.2   -1.00   -1.00   -1.00  113.16  32.10  \n",
       "315571  144.3   -1.00   -1.00   -1.00  113.39  39.00  \n",
       "\n",
       "[27504 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.CEN != -1] #Elimina valores negativos en la columna de salida\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer='normal', activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>...</th>\n",
       "      <th>model1251</th>\n",
       "      <th>model1252</th>\n",
       "      <th>model1253</th>\n",
       "      <th>model1254</th>\n",
       "      <th>model1255</th>\n",
       "      <th>model1256</th>\n",
       "      <th>model1257</th>\n",
       "      <th>model1258</th>\n",
       "      <th>model1259</th>\n",
       "      <th>model1260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epochs</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hidden_neurons</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hidden_layers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_train</td>\n",
       "      <td>0.767177493139766</td>\n",
       "      <td>0.7731823564405294</td>\n",
       "      <td>0.7780088849659437</td>\n",
       "      <td>0.7639709965842975</td>\n",
       "      <td>0.7443761739638564</td>\n",
       "      <td>0.7485955263466167</td>\n",
       "      <td>0.7447819158669</td>\n",
       "      <td>0.7743928212944475</td>\n",
       "      <td>0.7605766571428063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8743118756089514</td>\n",
       "      <td>0.8379421373019184</td>\n",
       "      <td>0.8817088906088432</td>\n",
       "      <td>0.8623310446962773</td>\n",
       "      <td>0.8813360701690305</td>\n",
       "      <td>0.8386252635530339</td>\n",
       "      <td>0.879685679252549</td>\n",
       "      <td>0.8665445848303253</td>\n",
       "      <td>0.8740642065917972</td>\n",
       "      <td>0.881184186776162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r2_test</td>\n",
       "      <td>0.7729807985170473</td>\n",
       "      <td>0.7863405567465785</td>\n",
       "      <td>0.7873429586392116</td>\n",
       "      <td>0.7615581295732288</td>\n",
       "      <td>0.7477935499990529</td>\n",
       "      <td>0.7549564420063439</td>\n",
       "      <td>0.7505409061706845</td>\n",
       "      <td>0.7777078330199059</td>\n",
       "      <td>0.7660937078405978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7521476346579116</td>\n",
       "      <td>0.7835933074432411</td>\n",
       "      <td>0.7780620619541616</td>\n",
       "      <td>0.760399305220298</td>\n",
       "      <td>0.764375972529673</td>\n",
       "      <td>0.7503914483105985</td>\n",
       "      <td>0.7658356805633514</td>\n",
       "      <td>0.7920441935959</td>\n",
       "      <td>0.7658092798421967</td>\n",
       "      <td>0.7659200814292269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 1261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              model1              model2              model3  \\\n",
       "0          epochs                  50                  50                  50   \n",
       "1  hidden_neurons                   5                   5                   5   \n",
       "2   hidden_layers                   1                   1                   1   \n",
       "3      activation                relu                relu                relu   \n",
       "4        r2_train   0.767177493139766  0.7731823564405294  0.7780088849659437   \n",
       "5         r2_test  0.7729807985170473  0.7863405567465785  0.7873429586392116   \n",
       "\n",
       "               model4              model5              model6  \\\n",
       "0                  50                  50                  50   \n",
       "1                   5                   5                   5   \n",
       "2                   1                   1                   1   \n",
       "3                relu                relu                relu   \n",
       "4  0.7639709965842975  0.7443761739638564  0.7485955263466167   \n",
       "5  0.7615581295732288  0.7477935499990529  0.7549564420063439   \n",
       "\n",
       "               model7              model8              model9  ...  \\\n",
       "0                  50                  50                  50  ...   \n",
       "1                   5                   5                   5  ...   \n",
       "2                   1                   2                   2  ...   \n",
       "3                relu                relu                relu  ...   \n",
       "4     0.7447819158669  0.7743928212944475  0.7605766571428063  ...   \n",
       "5  0.7505409061706845  0.7777078330199059  0.7660937078405978  ...   \n",
       "\n",
       "            model1251           model1252           model1253  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                   9                   9                   9   \n",
       "3                relu                relu                relu   \n",
       "4  0.8743118756089514  0.8379421373019184  0.8817088906088432   \n",
       "5  0.7521476346579116  0.7835933074432411  0.7780620619541616   \n",
       "\n",
       "            model1254           model1255           model1256  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4  0.8623310446962773  0.8813360701690305  0.8386252635530339   \n",
       "5   0.760399305220298   0.764375972529673  0.7503914483105985   \n",
       "\n",
       "            model1257           model1258           model1259  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4   0.879685679252549  0.8665445848303253  0.8740642065917972   \n",
       "5  0.7658356805633514     0.7920441935959  0.7658092798421967   \n",
       "\n",
       "            model1260  \n",
       "0                 200  \n",
       "1                 100  \n",
       "2                  10  \n",
       "3                relu  \n",
       "4   0.881184186776162  \n",
       "5  0.7659200814292269  \n",
       "\n",
       "[6 rows x 1261 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = pd.read_csv('../data/nn_models_vRegL1.csv')\n",
    "nn.loc[nn['Unnamed: 0']==0, ['Unnamed: 0']]='epochs'\n",
    "nn.loc[nn['Unnamed: 0']==1, ['Unnamed: 0']]='hidden_neurons'\n",
    "nn.loc[nn['Unnamed: 0']==2, ['Unnamed: 0']]='hidden_layers'\n",
    "nn.loc[nn['Unnamed: 0']==3, ['Unnamed: 0']]='activation'\n",
    "nn.loc[nn['Unnamed: 0']==4, ['Unnamed: 0']]='r2_train'\n",
    "nn.loc[nn['Unnamed: 0']==5, ['Unnamed: 0']]='r2_test'\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_80 = list(nn.iloc[5,1:].astype('float')>=0.8)\n",
    "indices = [i for i, x in enumerate(nn_80) if x == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(models, orient='index').to_csv('nn_models_vRegL1_fullstats_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for different seeds in train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 1 \n",
      "Accuracy for training is: 0.8318593755872391 Accuracy for test is: 0.7810651062934928 \n",
      "MSE for training is: 108.15120140080363 MSE for test is: 155.71221423697233 \n",
      "MAE for training is: 6.887651565806508 MAE for test is: 7.672460394163614 \n",
      "RMSE for training is: 10.399576981820156 RMSE for test is: 12.478470027890932\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 2 \n",
      "Accuracy for training is: 0.8193720905692796 Accuracy for test is: 0.7800459413527345 \n",
      "MSE for training is: 115.69912392572527 MSE for test is: 158.27755289311105 \n",
      "MAE for training is: 7.073720148255018 MAE for test is: 7.791312687783965 \n",
      "RMSE for training is: 10.75635272412193 RMSE for test is: 12.580840706928573\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 3 \n",
      "Accuracy for training is: 0.8236289617336441 Accuracy for test is: 0.7556013132036699 \n",
      "MSE for training is: 116.63263886710284 MSE for test is: 160.65804815238147 \n",
      "MAE for training is: 7.290839725224621 MAE for test is: 8.018453525229898 \n",
      "RMSE for training is: 10.799659201433295 RMSE for test is: 12.675095587504714\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 4 \n",
      "Accuracy for training is: 0.827666798496867 Accuracy for test is: 0.7854980323375645 \n",
      "MSE for training is: 114.4570335583547 MSE for test is: 139.15920166553983 \n",
      "MAE for training is: 7.063608620325262 MAE for test is: 7.4954917722292045 \n",
      "RMSE for training is: 10.698459401164016 RMSE for test is: 11.796575844945\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 5 \n",
      "Accuracy for training is: 0.8348501168903688 Accuracy for test is: 0.7860931220062519 \n",
      "MSE for training is: 111.17527095866394 MSE for test is: 132.94993911323138 \n",
      "MAE for training is: 7.08623756387947 MAE for test is: 7.824219176031047 \n",
      "RMSE for training is: 10.543968463470666 RMSE for test is: 11.53039197569759\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 6 \n",
      "Accuracy for training is: 0.8456363842948181 Accuracy for test is: 0.7732722704022781 \n",
      "MSE for training is: 102.11199052538585 MSE for test is: 148.90150119840885 \n",
      "MAE for training is: 6.731786751764145 MAE for test is: 7.601938514540264 \n",
      "RMSE for training is: 10.105047774522683 RMSE for test is: 12.202520280598138\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 7 \n",
      "Accuracy for training is: 0.8485790750662969 Accuracy for test is: 0.755611771410196 \n",
      "MSE for training is: 98.42938735934125 MSE for test is: 168.8586068215049 \n",
      "MAE for training is: 6.741603017294756 MAE for test is: 7.873188422769222 \n",
      "RMSE for training is: 9.921158569408174 RMSE for test is: 12.994560662889103\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 8 \n",
      "Accuracy for training is: 0.8384540952182956 Accuracy for test is: 0.7847779038252634 \n",
      "MSE for training is: 107.51745897740405 MSE for test is: 138.72677551979694 \n",
      "MAE for training is: 6.857328689460725 MAE for test is: 7.557543172037415 \n",
      "RMSE for training is: 10.369062589135241 RMSE for test is: 11.778233123851681\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 9 \n",
      "Accuracy for training is: 0.8256867762148634 Accuracy for test is: 0.7725275226823223 \n",
      "MSE for training is: 118.10600091487548 MSE for test is: 138.3878717028481 \n",
      "MAE for training is: 7.274260189120116 MAE for test is: 7.502804485286926 \n",
      "RMSE for training is: 10.867658483540762 RMSE for test is: 11.763837456495567\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 10 \n",
      "Accuracy for training is: 0.8386156059556363 Accuracy for test is: 0.7883678920609201 \n",
      "MSE for training is: 105.27521731329026 MSE for test is: 144.7934632636007 \n",
      "MAE for training is: 6.900836119280458 MAE for test is: 7.6984257894438874 \n",
      "RMSE for training is: 10.260371207382814 RMSE for test is: 12.033015551539885\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 11 \n",
      "Accuracy for training is: 0.8440352722487666 Accuracy for test is: 0.7832055754535584 \n",
      "MSE for training is: 102.39941550761804 MSE for test is: 145.59565504238074 \n",
      "MAE for training is: 6.968543421238342 MAE for test is: 7.774445267927515 \n",
      "RMSE for training is: 10.119259632385072 RMSE for test is: 12.066302459427277\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 12 \n",
      "Accuracy for training is: 0.8410008546036292 Accuracy for test is: 0.7772074851088889 \n",
      "MSE for training is: 106.64184124281739 MSE for test is: 140.11660872750517 \n",
      "MAE for training is: 6.894298929742725 MAE for test is: 7.5932935127357615 \n",
      "RMSE for training is: 10.326753664284697 RMSE for test is: 11.837086158658522\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 13 \n",
      "Accuracy for training is: 0.8417533399919463 Accuracy for test is: 0.7863612894662136 \n",
      "MSE for training is: 103.85230058747116 MSE for test is: 143.6469289779804 \n",
      "MAE for training is: 6.7431310573545264 MAE for test is: 7.722884051010593 \n",
      "RMSE for training is: 10.190794894779856 RMSE for test is: 11.985279678755118\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 14 \n",
      "Accuracy for training is: 0.8482572540560321 Accuracy for test is: 0.787660633102109 \n",
      "MSE for training is: 100.13053308994847 MSE for test is: 140.4914484789242 \n",
      "MAE for training is: 6.775960191440324 MAE for test is: 7.7017652142623465 \n",
      "RMSE for training is: 10.00652452602543 RMSE for test is: 11.852908861495738\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 15 \n",
      "Accuracy for training is: 0.8481985770321305 Accuracy for test is: 0.7685288508966334 \n",
      "MSE for training is: 98.61910696224778 MSE for test is: 160.23172700414395 \n",
      "MAE for training is: 6.651962077056413 MAE for test is: 7.8254217291287445 \n",
      "RMSE for training is: 9.930715329836405 RMSE for test is: 12.658267140653335\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 16 \n",
      "Accuracy for training is: 0.8274648871692176 Accuracy for test is: 0.7567488826384784 \n",
      "MSE for training is: 114.83088847045595 MSE for test is: 156.79261966582092 \n",
      "MAE for training is: 7.3646177953746355 MAE for test is: 8.098066563184348 \n",
      "RMSE for training is: 10.71591752816603 RMSE for test is: 12.521685975371724\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 17 \n",
      "Accuracy for training is: 0.8429164508973284 Accuracy for test is: 0.787520732014908 \n",
      "MSE for training is: 102.7314009993421 MSE for test is: 144.3321333751225 \n",
      "MAE for training is: 6.6899628495759735 MAE for test is: 7.6754359384187785 \n",
      "RMSE for training is: 10.135650003790685 RMSE for test is: 12.013830920032232\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 18 \n",
      "Accuracy for training is: 0.8216607613294518 Accuracy for test is: 0.7685983210252708 \n",
      "MSE for training is: 117.93783231981385 MSE for test is: 152.10432251852018 \n",
      "MAE for training is: 7.381265652363629 MAE for test is: 8.074848090922714 \n",
      "RMSE for training is: 10.859918614787768 RMSE for test is: 12.333058117049484\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 19 \n",
      "Accuracy for training is: 0.8410885900735924 Accuracy for test is: 0.7662625401187443 \n",
      "MSE for training is: 104.77215981476436 MSE for test is: 155.02811507663657 \n",
      "MAE for training is: 6.957829518734635 MAE for test is: 7.832648684846724 \n",
      "RMSE for training is: 10.235827265774095 RMSE for test is: 12.451028675440297\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 20 \n",
      "Accuracy for training is: 0.8299211830862809 Accuracy for test is: 0.7903938338887586 \n",
      "MSE for training is: 114.2596644450146 MSE for test is: 131.1025762873872 \n",
      "MAE for training is: 7.062883250579183 MAE for test is: 7.507001756623153 \n",
      "RMSE for training is: 10.689231237325469 RMSE for test is: 11.450003331326467\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 21 \n",
      "Accuracy for training is: 0.826255063102443 Accuracy for test is: 0.7689146573867638 \n",
      "MSE for training is: 114.28814562015758 MSE for test is: 154.33556446698498 \n",
      "MAE for training is: 7.247345304976791 MAE for test is: 8.023109563399776 \n",
      "RMSE for training is: 10.690563391148176 RMSE for test is: 12.423186566536984\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 22 \n",
      "Accuracy for training is: 0.8372258720856532 Accuracy for test is: 0.7824955281777044 \n",
      "MSE for training is: 107.51841135050509 MSE for test is: 143.47392011193068 \n",
      "MAE for training is: 6.910523165334627 MAE for test is: 7.621406027975298 \n",
      "RMSE for training is: 10.369108512813678 RMSE for test is: 11.978059947751584\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 23 \n",
      "Accuracy for training is: 0.8407265272075858 Accuracy for test is: 0.8007168576517333 \n",
      "MSE for training is: 105.9292436068947 MSE for test is: 128.74065291954707 \n",
      "MAE for training is: 6.877179095789377 MAE for test is: 7.53358005816053 \n",
      "RMSE for training is: 10.29219333314793 RMSE for test is: 11.346393828858007\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 24 \n",
      "Accuracy for training is: 0.8216373304146823 Accuracy for test is: 0.7980413441094755 \n",
      "MSE for training is: 118.33821389365127 MSE for test is: 131.43195535656508 \n",
      "MAE for training is: 7.520556936925064 MAE for test is: 7.815448235397494 \n",
      "RMSE for training is: 10.878336908445668 RMSE for test is: 11.464377669832981\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 25 \n",
      "Accuracy for training is: 0.8390617299359937 Accuracy for test is: 0.7941310785172087 \n",
      "MSE for training is: 104.43097373981155 MSE for test is: 142.9791329917134 \n",
      "MAE for training is: 6.999694601849159 MAE for test is: 7.734172354810802 \n",
      "RMSE for training is: 10.219147407676022 RMSE for test is: 11.95738821782221\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 26 \n",
      "Accuracy for training is: 0.8258711356198044 Accuracy for test is: 0.7931905687939218 \n",
      "MSE for training is: 115.29275164733798 MSE for test is: 135.43256655540955 \n",
      "MAE for training is: 7.104774864662519 MAE for test is: 7.680973565335743 \n",
      "RMSE for training is: 10.737446234898593 RMSE for test is: 11.637549851897932\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 27 \n",
      "Accuracy for training is: 0.8353565616458993 Accuracy for test is: 0.7926001727604535 \n",
      "MSE for training is: 108.19533779889271 MSE for test is: 138.90468051117884 \n",
      "MAE for training is: 6.836926388558385 MAE for test is: 7.561702348481089 \n",
      "RMSE for training is: 10.401698793893846 RMSE for test is: 11.785782982525125\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 28 \n",
      "Accuracy for training is: 0.8573480070312796 Accuracy for test is: 0.7874474909897244 \n",
      "MSE for training is: 92.63672769131196 MSE for test is: 147.2929025495292 \n",
      "MAE for training is: 6.534852608655863 MAE for test is: 7.806449397963414 \n",
      "RMSE for training is: 9.624797540276468 RMSE for test is: 12.136428739523385\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 29 \n",
      "Accuracy for training is: 0.8405612208672729 Accuracy for test is: 0.7807642704649228 \n",
      "MSE for training is: 107.20994599008452 MSE for test is: 136.7648925521356 \n",
      "MAE for training is: 7.003489098490082 MAE for test is: 7.664699542102181 \n",
      "RMSE for training is: 10.35422358219507 RMSE for test is: 11.694652305739389\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 30 \n",
      "Accuracy for training is: 0.8213695456597884 Accuracy for test is: 0.7939002670087761 \n",
      "MSE for training is: 116.04649472669426 MSE for test is: 142.66579305782759 \n",
      "MAE for training is: 7.344584636838394 MAE for test is: 7.891127346499567 \n",
      "RMSE for training is: 10.772487861524572 RMSE for test is: 11.944278674655394\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 31 \n",
      "Accuracy for training is: 0.8401396593263978 Accuracy for test is: 0.7923195495012405 \n",
      "MSE for training is: 105.36216620318127 MSE for test is: 137.89663915811937 \n",
      "MAE for training is: 6.890416682988792 MAE for test is: 7.567654911549441 \n",
      "RMSE for training is: 10.264607454899641 RMSE for test is: 11.742939970813074\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 32 \n",
      "Accuracy for training is: 0.8329705252889663 Accuracy for test is: 0.7733319688780542 \n",
      "MSE for training is: 108.73353289196469 MSE for test is: 155.9912701023057 \n",
      "MAE for training is: 6.840507584765549 MAE for test is: 7.807566177134184 \n",
      "RMSE for training is: 10.427537240018118 RMSE for test is: 12.489646516307245\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 33 \n",
      "Accuracy for training is: 0.8467108992209714 Accuracy for test is: 0.7834702056923283 \n",
      "MSE for training is: 101.05882989398879 MSE for test is: 143.65530503562124 \n",
      "MAE for training is: 6.683669504855246 MAE for test is: 7.626167194321796 \n",
      "RMSE for training is: 10.05280209165528 RMSE for test is: 11.985629104707906\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 34 \n",
      "Accuracy for training is: 0.8354447632938522 Accuracy for test is: 0.7885139737441857 \n",
      "MSE for training is: 108.47798281357566 MSE for test is: 140.32469449935806 \n",
      "MAE for training is: 6.9475672033315305 MAE for test is: 7.757633199321177 \n",
      "RMSE for training is: 10.415276415610661 RMSE for test is: 11.845872466785975\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 35 \n",
      "Accuracy for training is: 0.8389170930331296 Accuracy for test is: 0.7749469607647862 \n",
      "MSE for training is: 106.75116148086451 MSE for test is: 146.9848280951526 \n",
      "MAE for training is: 6.844152589349003 MAE for test is: 7.693708672811292 \n",
      "RMSE for training is: 10.332045367731624 RMSE for test is: 12.123729958026638\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 36 \n",
      "Accuracy for training is: 0.8478556478558041 Accuracy for test is: 0.7688344702902864 \n",
      "MSE for training is: 103.13739089088953 MSE for test is: 140.3319904002196 \n",
      "MAE for training is: 6.740155547027212 MAE for test is: 7.653968178625367 \n",
      "RMSE for training is: 10.155658072763652 RMSE for test is: 11.846180413965492\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 37 \n",
      "Accuracy for training is: 0.8125826136653571 Accuracy for test is: 0.784643549046315 \n",
      "MSE for training is: 126.59286970683584 MSE for test is: 132.329096998905 \n",
      "MAE for training is: 7.350658856136561 MAE for test is: 7.568251406181129 \n",
      "RMSE for training is: 11.2513496837862 RMSE for test is: 11.503438485900856\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 38 \n",
      "Accuracy for training is: 0.8202664769695981 Accuracy for test is: 0.7729768191965569 \n",
      "MSE for training is: 119.65545833172284 MSE for test is: 146.18855950075425 \n",
      "MAE for training is: 7.241181086738835 MAE for test is: 7.5683861434633055 \n",
      "RMSE for training is: 10.938713742105277 RMSE for test is: 12.090846103592348\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 39 \n",
      "Accuracy for training is: 0.8262098214093032 Accuracy for test is: 0.7870972759927946 \n",
      "MSE for training is: 114.0042372176784 MSE for test is: 143.32858391084463 \n",
      "MAE for training is: 7.063351264529665 MAE for test is: 7.669482733228305 \n",
      "RMSE for training is: 10.677276676085452 RMSE for test is: 11.971991643450334\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 40 \n",
      "Accuracy for training is: 0.8186169254826638 Accuracy for test is: 0.807679865811074 \n",
      "MSE for training is: 118.48364736248818 MSE for test is: 131.0421995131407 \n",
      "MAE for training is: 7.181305220523221 MAE for test is: 7.533320638152873 \n",
      "RMSE for training is: 10.88501940110757 RMSE for test is: 11.447366488111609\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 41 \n",
      "Accuracy for training is: 0.8130999351013128 Accuracy for test is: 0.7590993799770767 \n",
      "MSE for training is: 124.44319117267058 MSE for test is: 155.08434164917318 \n",
      "MAE for training is: 7.426937072298475 MAE for test is: 7.921052342714301 \n",
      "RMSE for training is: 11.155410847327435 RMSE for test is: 12.45328637947322\n"
     ]
    }
   ],
   "source": [
    "i = 789\n",
    "nh = int(nn.iloc[:,i+1]['hidden_neurons'])\n",
    "hl = int(nn.iloc[:,i+1]['hidden_layers'])\n",
    "e = int(nn.iloc[:,i+1]['epochs'])\n",
    "a = nn.iloc[:,i+1]['activation']\n",
    "\n",
    "models = {}\n",
    "r = 0.01\n",
    "\n",
    "rndm = [x for x in range(1, 101)]\n",
    "\n",
    "for rnd in rndm:\n",
    "    \n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.25, random_state=rnd) #split\n",
    "    \n",
    "    model = neuron_layers(10,nh,1,hl,a,r)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "    #statistics for train\n",
    "    y_hat= model.predict(X_train)\n",
    "    acc_train = r2_score(Y_train, y_hat)\n",
    "    mse_train = mean_squared_error(Y_train, y_hat)\n",
    "    mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "    rmse_train = mean_squared_error(Y_train, y_hat, squared=False)    \n",
    "\n",
    "    #accuracy for test\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc_test = r2_score(Y_test, y_hat)\n",
    "    mse_test = mean_squared_error(Y_test, y_hat)\n",
    "    mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "    rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "    models['model'+str(i+1)+'-'+str(r)] = [e, nh, hl, a, r, rnd, acc_train, mse_train, mae_train, rmse_train, acc_test, mse_test, mae_test, rmse_test]\n",
    "\n",
    "    print ('\\n*For model',str(i+1),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "           '-regularization cost:',r,'-random_state:',rnd,\n",
    "           '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test),\n",
    "          '\\nMSE for training is:', str(mse_train),'MSE for test is:',str(mse_test),\n",
    "           '\\nMAE for training is:', str(mae_train),'MAE for test is:',str(mae_test),\n",
    "           '\\nRMSE for training is:', str(rmse_train),'RMSE for test is:',str(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
