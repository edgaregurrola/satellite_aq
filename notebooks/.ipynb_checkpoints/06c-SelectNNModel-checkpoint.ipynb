{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "plt.style.use('seaborn-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315535</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>19:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>18.10</td>\n",
       "      <td>22.27</td>\n",
       "      <td>84.00</td>\n",
       "      <td>46.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>12.68</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315544</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>20:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>27.51</td>\n",
       "      <td>84.40</td>\n",
       "      <td>57.4</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315553</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>28.60</td>\n",
       "      <td>75.30</td>\n",
       "      <td>151.5</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>6.86</td>\n",
       "      <td>22.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315562</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.43</td>\n",
       "      <td>125.60</td>\n",
       "      <td>174.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.16</td>\n",
       "      <td>32.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315571</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>23:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>58.20</td>\n",
       "      <td>66.09</td>\n",
       "      <td>141.50</td>\n",
       "      <td>144.3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.39</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FECHA   HORA PARAM    AGU     ATM     CEN     LDO  \\\n",
       "4       2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04   \n",
       "13      2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27   \n",
       "22      2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00   \n",
       "31      2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65   \n",
       "40      2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70   \n",
       "...                     ...    ...   ...    ...     ...     ...     ...   \n",
       "315535  2019-12-31 19:00:00  19:00  PM10  -1.00   18.10   22.27   84.00   \n",
       "315544  2019-12-31 20:00:00  20:00  PM10  -1.00   -1.00   27.51   84.40   \n",
       "315553  2019-12-31 21:00:00  21:00  PM10  -1.00   -1.00   28.60   75.30   \n",
       "315562  2019-12-31 22:00:00  22:00  PM10  -1.00   -1.00   50.43  125.60   \n",
       "315571  2019-12-31 23:00:00  23:00  PM10  -1.00   58.20   66.09  141.50   \n",
       "\n",
       "         LPIN     MIR     OBL     SFE     TLA    VAL  \n",
       "4        -1.0   69.75  197.67  115.54  143.40  17.08  \n",
       "13       -1.0   68.99  138.09   84.24  100.46  29.15  \n",
       "22       -1.0  117.70   98.79  135.39   82.05  30.89  \n",
       "31       -1.0  160.30   97.94  117.60  114.74  38.74  \n",
       "40       -1.0  180.89  134.39  164.68  118.83  51.48  \n",
       "...       ...     ...     ...     ...     ...    ...  \n",
       "315535   46.2   -1.00   -1.00   -1.00   12.68  16.20  \n",
       "315544   57.4   -1.00   -1.00   -1.00   50.31  14.00  \n",
       "315553  151.5   -1.00   -1.00   -1.00    6.86  22.90  \n",
       "315562  174.2   -1.00   -1.00   -1.00  113.16  32.10  \n",
       "315571  144.3   -1.00   -1.00   -1.00  113.39  39.00  \n",
       "\n",
       "[27504 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.CEN != -1] #Elimina valores negativos en la columna de salida\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer='normal', activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>...</th>\n",
       "      <th>model1251</th>\n",
       "      <th>model1252</th>\n",
       "      <th>model1253</th>\n",
       "      <th>model1254</th>\n",
       "      <th>model1255</th>\n",
       "      <th>model1256</th>\n",
       "      <th>model1257</th>\n",
       "      <th>model1258</th>\n",
       "      <th>model1259</th>\n",
       "      <th>model1260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epochs</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hidden_neurons</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hidden_layers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_train</td>\n",
       "      <td>0.767177493139766</td>\n",
       "      <td>0.7731823564405294</td>\n",
       "      <td>0.7780088849659437</td>\n",
       "      <td>0.7639709965842975</td>\n",
       "      <td>0.7443761739638564</td>\n",
       "      <td>0.7485955263466167</td>\n",
       "      <td>0.7447819158669</td>\n",
       "      <td>0.7743928212944475</td>\n",
       "      <td>0.7605766571428063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8743118756089514</td>\n",
       "      <td>0.8379421373019184</td>\n",
       "      <td>0.8817088906088432</td>\n",
       "      <td>0.8623310446962773</td>\n",
       "      <td>0.8813360701690305</td>\n",
       "      <td>0.8386252635530339</td>\n",
       "      <td>0.879685679252549</td>\n",
       "      <td>0.8665445848303253</td>\n",
       "      <td>0.8740642065917972</td>\n",
       "      <td>0.881184186776162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r2_test</td>\n",
       "      <td>0.7729807985170473</td>\n",
       "      <td>0.7863405567465785</td>\n",
       "      <td>0.7873429586392116</td>\n",
       "      <td>0.7615581295732288</td>\n",
       "      <td>0.7477935499990529</td>\n",
       "      <td>0.7549564420063439</td>\n",
       "      <td>0.7505409061706845</td>\n",
       "      <td>0.7777078330199059</td>\n",
       "      <td>0.7660937078405978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7521476346579116</td>\n",
       "      <td>0.7835933074432411</td>\n",
       "      <td>0.7780620619541616</td>\n",
       "      <td>0.760399305220298</td>\n",
       "      <td>0.764375972529673</td>\n",
       "      <td>0.7503914483105985</td>\n",
       "      <td>0.7658356805633514</td>\n",
       "      <td>0.7920441935959</td>\n",
       "      <td>0.7658092798421967</td>\n",
       "      <td>0.7659200814292269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 1261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              model1              model2              model3  \\\n",
       "0          epochs                  50                  50                  50   \n",
       "1  hidden_neurons                   5                   5                   5   \n",
       "2   hidden_layers                   1                   1                   1   \n",
       "3      activation                relu                relu                relu   \n",
       "4        r2_train   0.767177493139766  0.7731823564405294  0.7780088849659437   \n",
       "5         r2_test  0.7729807985170473  0.7863405567465785  0.7873429586392116   \n",
       "\n",
       "               model4              model5              model6  \\\n",
       "0                  50                  50                  50   \n",
       "1                   5                   5                   5   \n",
       "2                   1                   1                   1   \n",
       "3                relu                relu                relu   \n",
       "4  0.7639709965842975  0.7443761739638564  0.7485955263466167   \n",
       "5  0.7615581295732288  0.7477935499990529  0.7549564420063439   \n",
       "\n",
       "               model7              model8              model9  ...  \\\n",
       "0                  50                  50                  50  ...   \n",
       "1                   5                   5                   5  ...   \n",
       "2                   1                   2                   2  ...   \n",
       "3                relu                relu                relu  ...   \n",
       "4     0.7447819158669  0.7743928212944475  0.7605766571428063  ...   \n",
       "5  0.7505409061706845  0.7777078330199059  0.7660937078405978  ...   \n",
       "\n",
       "            model1251           model1252           model1253  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                   9                   9                   9   \n",
       "3                relu                relu                relu   \n",
       "4  0.8743118756089514  0.8379421373019184  0.8817088906088432   \n",
       "5  0.7521476346579116  0.7835933074432411  0.7780620619541616   \n",
       "\n",
       "            model1254           model1255           model1256  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4  0.8623310446962773  0.8813360701690305  0.8386252635530339   \n",
       "5   0.760399305220298   0.764375972529673  0.7503914483105985   \n",
       "\n",
       "            model1257           model1258           model1259  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4   0.879685679252549  0.8665445848303253  0.8740642065917972   \n",
       "5  0.7658356805633514     0.7920441935959  0.7658092798421967   \n",
       "\n",
       "            model1260  \n",
       "0                 200  \n",
       "1                 100  \n",
       "2                  10  \n",
       "3                relu  \n",
       "4   0.881184186776162  \n",
       "5  0.7659200814292269  \n",
       "\n",
       "[6 rows x 1261 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = pd.read_csv('../data/nn_models_vRegL1.csv')\n",
    "nn.loc[nn['Unnamed: 0']==0, ['Unnamed: 0']]='epochs'\n",
    "nn.loc[nn['Unnamed: 0']==1, ['Unnamed: 0']]='hidden_neurons'\n",
    "nn.loc[nn['Unnamed: 0']==2, ['Unnamed: 0']]='hidden_layers'\n",
    "nn.loc[nn['Unnamed: 0']==3, ['Unnamed: 0']]='activation'\n",
    "nn.loc[nn['Unnamed: 0']==4, ['Unnamed: 0']]='r2_train'\n",
    "nn.loc[nn['Unnamed: 0']==5, ['Unnamed: 0']]='r2_test'\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_80 = list(nn.iloc[5,1:].astype('float')>=0.8)\n",
    "indices = [i for i, x in enumerate(nn_80) if x == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(models, orient='index').to_csv('nn_models_vRegL1_fullstats_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for different seeds in train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 1 \n",
      "Accuracy for training is: 0.8411286125958266 Accuracy for test is: 0.7825824620634125 \n",
      "MSE for training is: 103.30344859207045 MSE for test is: 152.25608871856898 \n",
      "MAE for training is: 6.844224496615397 MAE for test is: 7.780826673561433 \n",
      "RMSE for training is: 10.163830409450487 RMSE for test is: 12.33920940411374\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 2 \n",
      "Accuracy for training is: 0.8378729978775774 Accuracy for test is: 0.7866936488675909 \n",
      "MSE for training is: 104.30724899176036 MSE for test is: 155.28305651128778 \n",
      "MAE for training is: 6.949140598170428 MAE for test is: 7.874360911856996 \n",
      "RMSE for training is: 10.213092038739314 RMSE for test is: 12.46126223587674\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 3 \n",
      "Accuracy for training is: 0.8319507205717828 Accuracy for test is: 0.7816677188019685 \n",
      "MSE for training is: 110.82052539073557 MSE for test is: 144.9193147533735 \n",
      "MAE for training is: 6.964852873764889 MAE for test is: 7.657719747709417 \n",
      "RMSE for training is: 10.527132819088756 RMSE for test is: 12.038243840086206\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 4 \n",
      "Accuracy for training is: 0.8440850229353463 Accuracy for test is: 0.7684818842802696 \n",
      "MSE for training is: 102.90428776287175 MSE for test is: 153.16214842431359 \n",
      "MAE for training is: 6.952894995961976 MAE for test is: 7.894153346067082 \n",
      "RMSE for training is: 10.144175065665603 RMSE for test is: 12.375869602751703\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 5 \n",
      "Accuracy for training is: 0.84976126568804 Accuracy for test is: 0.7820362773656184 \n",
      "MSE for training is: 100.83118393355622 MSE for test is: 134.4392051774936 \n",
      "MAE for training is: 6.7794410751000305 MAE for test is: 7.683650653189344 \n",
      "RMSE for training is: 10.041473195381055 RMSE for test is: 11.594792157580644\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 6 \n",
      "Accuracy for training is: 0.837447717683147 Accuracy for test is: 0.7873485100046809 \n",
      "MSE for training is: 107.80147291686708 MSE for test is: 137.97714493713505 \n",
      "MAE for training is: 6.96913090339572 MAE for test is: 7.558234557753541 \n",
      "RMSE for training is: 10.382748813145152 RMSE for test is: 11.746367308114243\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 7 \n",
      "Accuracy for training is: 0.8495374449054216 Accuracy for test is: 0.7589222310971835 \n",
      "MSE for training is: 97.5430404265795 MSE for test is: 170.70669138107775 \n",
      "MAE for training is: 6.65862875568215 MAE for test is: 7.75403888369924 \n",
      "RMSE for training is: 9.876388025314695 RMSE for test is: 13.065477082031018\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 8 \n",
      "Accuracy for training is: 0.8421423256096928 Accuracy for test is: 0.7980463724419762 \n",
      "MSE for training is: 104.37877657368475 MSE for test is: 132.60729585540358 \n",
      "MAE for training is: 6.819219645574343 MAE for test is: 7.54470770450142 \n",
      "RMSE for training is: 10.216593198012964 RMSE for test is: 11.515524124216126\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 9 \n",
      "Accuracy for training is: 0.8277497161535297 Accuracy for test is: 0.7736042375047967 \n",
      "MSE for training is: 115.6493144501466 MSE for test is: 139.40023203169912 \n",
      "MAE for training is: 7.040523093726523 MAE for test is: 7.4131190458442315 \n",
      "RMSE for training is: 10.754037123338685 RMSE for test is: 11.806787540719919\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 10 \n",
      "Accuracy for training is: 0.8235167319832764 Accuracy for test is: 0.7749110073832746 \n",
      "MSE for training is: 115.709781436659 MSE for test is: 152.81160540290685 \n",
      "MAE for training is: 7.076448884195952 MAE for test is: 7.712412775418819 \n",
      "RMSE for training is: 10.756848118136604 RMSE for test is: 12.361699130900528\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 11 \n",
      "Accuracy for training is: 0.8369754888243733 Accuracy for test is: 0.7763049231208549 \n",
      "MSE for training is: 107.27267904464277 MSE for test is: 149.7646520945064 \n",
      "MAE for training is: 6.858557866697185 MAE for test is: 7.6647837904743055 \n",
      "RMSE for training is: 10.357252485318815 RMSE for test is: 12.237836904228883\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 12 \n",
      "Accuracy for training is: 0.8257039434045228 Accuracy for test is: 0.7734873615163043 \n",
      "MSE for training is: 116.75335358498039 MSE for test is: 140.86329273077195 \n",
      "MAE for training is: 7.395797000536967 MAE for test is: 8.059680234212655 \n",
      "RMSE for training is: 10.805246576778357 RMSE for test is: 11.86858427660064\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 13 \n",
      "Accuracy for training is: 0.8238028073210721 Accuracy for test is: 0.7838564327662499 \n",
      "MSE for training is: 116.32557207713582 MSE for test is: 142.81060056305682 \n",
      "MAE for training is: 7.106253784939662 MAE for test is: 7.706187924712902 \n",
      "RMSE for training is: 10.785433328204101 RMSE for test is: 11.950338930886305\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 14 \n",
      "Accuracy for training is: 0.8297523027565383 Accuracy for test is: 0.7720131572289417 \n",
      "MSE for training is: 113.4091384595462 MSE for test is: 145.21619905783896 \n",
      "MAE for training is: 7.317076659790868 MAE for test is: 7.9636187147517745 \n",
      "RMSE for training is: 10.649372679155622 RMSE for test is: 12.050568412230145\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 15 \n",
      "Accuracy for training is: 0.8310095820720554 Accuracy for test is: 0.7818648043764699 \n",
      "MSE for training is: 110.46557854336358 MSE for test is: 149.81414860313774 \n",
      "MAE for training is: 7.127998770121352 MAE for test is: 7.631318763212125 \n",
      "RMSE for training is: 10.510260631562073 RMSE for test is: 12.239859010754076\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 16 \n",
      "Accuracy for training is: 0.8362523225931472 Accuracy for test is: 0.7827434307441506 \n",
      "MSE for training is: 108.247374886639 MSE for test is: 142.8042554474837 \n",
      "MAE for training is: 6.959828195792733 MAE for test is: 7.584770684284159 \n",
      "RMSE for training is: 10.40419986768031 RMSE for test is: 11.950073449459786\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 17 \n",
      "Accuracy for training is: 0.8221588188781505 Accuracy for test is: 0.7745665288997218 \n",
      "MSE for training is: 115.90833601312502 MSE for test is: 156.56986245415365 \n",
      "MAE for training is: 7.390072418277558 MAE for test is: 8.231066894822156 \n",
      "RMSE for training is: 10.76607337951609 RMSE for test is: 12.512787956892486\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 18 \n",
      "Accuracy for training is: 0.8381321599884024 Accuracy for test is: 0.7888790188051761 \n",
      "MSE for training is: 105.95175990800716 MSE for test is: 144.20983501847437 \n",
      "MAE for training is: 6.94768354287048 MAE for test is: 7.758662562932866 \n",
      "RMSE for training is: 10.293287128415644 RMSE for test is: 12.008739942994618\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 19 \n",
      "Accuracy for training is: 0.8453050297197143 Accuracy for test is: 0.7805778747414938 \n",
      "MSE for training is: 102.15015604823712 MSE for test is: 144.86177279585627 \n",
      "MAE for training is: 6.8447978132413745 MAE for test is: 7.566591969124081 \n",
      "RMSE for training is: 10.106936036615505 RMSE for test is: 12.035853638020706\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 20 \n",
      "Accuracy for training is: 0.8415973619746194 Accuracy for test is: 0.7899460628928643 \n",
      "MSE for training is: 105.5591753244718 MSE for test is: 133.5011738661216 \n",
      "MAE for training is: 6.915828928826652 MAE for test is: 7.5812814564229 \n",
      "RMSE for training is: 10.274199497988727 RMSE for test is: 11.554270806334841\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 21 \n",
      "Accuracy for training is: 0.8217171469800169 Accuracy for test is: 0.786983743643925 \n",
      "MSE for training is: 116.4416241567535 MSE for test is: 146.7786771872247 \n",
      "MAE for training is: 7.093696601098513 MAE for test is: 7.631675103885698 \n",
      "RMSE for training is: 10.790812024901253 RMSE for test is: 12.115225015955119\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 22 \n",
      "Accuracy for training is: 0.8321181578268186 Accuracy for test is: 0.7825371889849476 \n",
      "MSE for training is: 110.37059788785146 MSE for test is: 146.09332137132645 \n",
      "MAE for training is: 7.0284571465269705 MAE for test is: 7.695125611219769 \n",
      "RMSE for training is: 10.505741186982071 RMSE for test is: 12.086907022531713\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 23 \n",
      "Accuracy for training is: 0.8338237111040636 Accuracy for test is: 0.7981755255153519 \n",
      "MSE for training is: 110.4181650015924 MSE for test is: 129.91668925969358 \n",
      "MAE for training is: 6.920875033801292 MAE for test is: 7.578679028912212 \n",
      "RMSE for training is: 10.508004805936872 RMSE for test is: 11.398100247834881\n"
     ]
    }
   ],
   "source": [
    "i = 789\n",
    "nh = int(nn.iloc[:,i+1]['hidden_neurons'])\n",
    "hl = int(nn.iloc[:,i+1]['hidden_layers'])\n",
    "e = int(nn.iloc[:,i+1]['epochs'])\n",
    "a = nn.iloc[:,i+1]['activation']\n",
    "\n",
    "models = {}\n",
    "r = 0.01\n",
    "\n",
    "rndm = [x for x in range(1, 101)]\n",
    "\n",
    "for rnd in rndm:\n",
    "    \n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2, random_state=rnd) #split\n",
    "    \n",
    "    model = neuron_layers(10,nh,1,hl,a,r)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "    #statistics for train\n",
    "    y_hat= model.predict(X_train)\n",
    "    acc_train = r2_score(Y_train, y_hat)\n",
    "    mse_train = mean_squared_error(Y_train, y_hat)\n",
    "    mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "    rmse_train = mean_squared_error(Y_train, y_hat, squared=False)    \n",
    "\n",
    "    #accuracy for test\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc_test = r2_score(Y_test, y_hat)\n",
    "    mse_test = mean_squared_error(Y_test, y_hat)\n",
    "    mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "    rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "    models['model'+str(i+1)+'-'+str(r)] = [e, nh, hl, a, r, rnd, acc_train, mse_train, mae_train, rmse_train, acc_test, mse_test, mae_test, rmse_test]\n",
    "\n",
    "    print ('\\n*For model',str(i+1),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "           '-regularization cost:',r,'-random_state:',rnd,\n",
    "           '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test),\n",
    "          '\\nMSE for training is:', str(mse_train),'MSE for test is:',str(mse_test),\n",
    "           '\\nMAE for training is:', str(mae_train),'MAE for test is:',str(mae_test),\n",
    "           '\\nRMSE for training is:', str(rmse_train),'RMSE for test is:',str(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
