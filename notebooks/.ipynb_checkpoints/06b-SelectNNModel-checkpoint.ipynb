{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "plt.style.use('seaborn-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315535</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>19:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>18.10</td>\n",
       "      <td>22.27</td>\n",
       "      <td>84.00</td>\n",
       "      <td>46.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>12.68</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315544</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>20:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>27.51</td>\n",
       "      <td>84.40</td>\n",
       "      <td>57.4</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315553</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>21:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>28.60</td>\n",
       "      <td>75.30</td>\n",
       "      <td>151.5</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>6.86</td>\n",
       "      <td>22.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315562</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>50.43</td>\n",
       "      <td>125.60</td>\n",
       "      <td>174.2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.16</td>\n",
       "      <td>32.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315571</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>23:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>58.20</td>\n",
       "      <td>66.09</td>\n",
       "      <td>141.50</td>\n",
       "      <td>144.3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>113.39</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27504 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FECHA   HORA PARAM    AGU     ATM     CEN     LDO  \\\n",
       "4       2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04   \n",
       "13      2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27   \n",
       "22      2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00   \n",
       "31      2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65   \n",
       "40      2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70   \n",
       "...                     ...    ...   ...    ...     ...     ...     ...   \n",
       "315535  2019-12-31 19:00:00  19:00  PM10  -1.00   18.10   22.27   84.00   \n",
       "315544  2019-12-31 20:00:00  20:00  PM10  -1.00   -1.00   27.51   84.40   \n",
       "315553  2019-12-31 21:00:00  21:00  PM10  -1.00   -1.00   28.60   75.30   \n",
       "315562  2019-12-31 22:00:00  22:00  PM10  -1.00   -1.00   50.43  125.60   \n",
       "315571  2019-12-31 23:00:00  23:00  PM10  -1.00   58.20   66.09  141.50   \n",
       "\n",
       "         LPIN     MIR     OBL     SFE     TLA    VAL  \n",
       "4        -1.0   69.75  197.67  115.54  143.40  17.08  \n",
       "13       -1.0   68.99  138.09   84.24  100.46  29.15  \n",
       "22       -1.0  117.70   98.79  135.39   82.05  30.89  \n",
       "31       -1.0  160.30   97.94  117.60  114.74  38.74  \n",
       "40       -1.0  180.89  134.39  164.68  118.83  51.48  \n",
       "...       ...     ...     ...     ...     ...    ...  \n",
       "315535   46.2   -1.00   -1.00   -1.00   12.68  16.20  \n",
       "315544   57.4   -1.00   -1.00   -1.00   50.31  14.00  \n",
       "315553  151.5   -1.00   -1.00   -1.00    6.86  22.90  \n",
       "315562  174.2   -1.00   -1.00   -1.00  113.16  32.10  \n",
       "315571  144.3   -1.00   -1.00   -1.00  113.39  39.00  \n",
       "\n",
       "[27504 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.CEN != -1] #Elimina valores negativos en la columna de salida\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer='normal', activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>...</th>\n",
       "      <th>model1251</th>\n",
       "      <th>model1252</th>\n",
       "      <th>model1253</th>\n",
       "      <th>model1254</th>\n",
       "      <th>model1255</th>\n",
       "      <th>model1256</th>\n",
       "      <th>model1257</th>\n",
       "      <th>model1258</th>\n",
       "      <th>model1259</th>\n",
       "      <th>model1260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epochs</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hidden_neurons</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hidden_layers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_train</td>\n",
       "      <td>0.767177493139766</td>\n",
       "      <td>0.7731823564405294</td>\n",
       "      <td>0.7780088849659437</td>\n",
       "      <td>0.7639709965842975</td>\n",
       "      <td>0.7443761739638564</td>\n",
       "      <td>0.7485955263466167</td>\n",
       "      <td>0.7447819158669</td>\n",
       "      <td>0.7743928212944475</td>\n",
       "      <td>0.7605766571428063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8743118756089514</td>\n",
       "      <td>0.8379421373019184</td>\n",
       "      <td>0.8817088906088432</td>\n",
       "      <td>0.8623310446962773</td>\n",
       "      <td>0.8813360701690305</td>\n",
       "      <td>0.8386252635530339</td>\n",
       "      <td>0.879685679252549</td>\n",
       "      <td>0.8665445848303253</td>\n",
       "      <td>0.8740642065917972</td>\n",
       "      <td>0.881184186776162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r2_test</td>\n",
       "      <td>0.7729807985170473</td>\n",
       "      <td>0.7863405567465785</td>\n",
       "      <td>0.7873429586392116</td>\n",
       "      <td>0.7615581295732288</td>\n",
       "      <td>0.7477935499990529</td>\n",
       "      <td>0.7549564420063439</td>\n",
       "      <td>0.7505409061706845</td>\n",
       "      <td>0.7777078330199059</td>\n",
       "      <td>0.7660937078405978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7521476346579116</td>\n",
       "      <td>0.7835933074432411</td>\n",
       "      <td>0.7780620619541616</td>\n",
       "      <td>0.760399305220298</td>\n",
       "      <td>0.764375972529673</td>\n",
       "      <td>0.7503914483105985</td>\n",
       "      <td>0.7658356805633514</td>\n",
       "      <td>0.7920441935959</td>\n",
       "      <td>0.7658092798421967</td>\n",
       "      <td>0.7659200814292269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 1261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              model1              model2              model3  \\\n",
       "0          epochs                  50                  50                  50   \n",
       "1  hidden_neurons                   5                   5                   5   \n",
       "2   hidden_layers                   1                   1                   1   \n",
       "3      activation                relu                relu                relu   \n",
       "4        r2_train   0.767177493139766  0.7731823564405294  0.7780088849659437   \n",
       "5         r2_test  0.7729807985170473  0.7863405567465785  0.7873429586392116   \n",
       "\n",
       "               model4              model5              model6  \\\n",
       "0                  50                  50                  50   \n",
       "1                   5                   5                   5   \n",
       "2                   1                   1                   1   \n",
       "3                relu                relu                relu   \n",
       "4  0.7639709965842975  0.7443761739638564  0.7485955263466167   \n",
       "5  0.7615581295732288  0.7477935499990529  0.7549564420063439   \n",
       "\n",
       "               model7              model8              model9  ...  \\\n",
       "0                  50                  50                  50  ...   \n",
       "1                   5                   5                   5  ...   \n",
       "2                   1                   2                   2  ...   \n",
       "3                relu                relu                relu  ...   \n",
       "4     0.7447819158669  0.7743928212944475  0.7605766571428063  ...   \n",
       "5  0.7505409061706845  0.7777078330199059  0.7660937078405978  ...   \n",
       "\n",
       "            model1251           model1252           model1253  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                   9                   9                   9   \n",
       "3                relu                relu                relu   \n",
       "4  0.8743118756089514  0.8379421373019184  0.8817088906088432   \n",
       "5  0.7521476346579116  0.7835933074432411  0.7780620619541616   \n",
       "\n",
       "            model1254           model1255           model1256  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4  0.8623310446962773  0.8813360701690305  0.8386252635530339   \n",
       "5   0.760399305220298   0.764375972529673  0.7503914483105985   \n",
       "\n",
       "            model1257           model1258           model1259  \\\n",
       "0                 200                 200                 200   \n",
       "1                 100                 100                 100   \n",
       "2                  10                  10                  10   \n",
       "3                relu                relu                relu   \n",
       "4   0.879685679252549  0.8665445848303253  0.8740642065917972   \n",
       "5  0.7658356805633514     0.7920441935959  0.7658092798421967   \n",
       "\n",
       "            model1260  \n",
       "0                 200  \n",
       "1                 100  \n",
       "2                  10  \n",
       "3                relu  \n",
       "4   0.881184186776162  \n",
       "5  0.7659200814292269  \n",
       "\n",
       "[6 rows x 1261 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = pd.read_csv('../data/nn_models_vRegL1.csv')\n",
    "nn.loc[nn['Unnamed: 0']==0, ['Unnamed: 0']]='epochs'\n",
    "nn.loc[nn['Unnamed: 0']==1, ['Unnamed: 0']]='hidden_neurons'\n",
    "nn.loc[nn['Unnamed: 0']==2, ['Unnamed: 0']]='hidden_layers'\n",
    "nn.loc[nn['Unnamed: 0']==3, ['Unnamed: 0']]='activation'\n",
    "nn.loc[nn['Unnamed: 0']==4, ['Unnamed: 0']]='r2_train'\n",
    "nn.loc[nn['Unnamed: 0']==5, ['Unnamed: 0']]='r2_test'\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_80 = list(nn.iloc[5,1:].astype('float')>=0.8)\n",
    "indices = [i for i, x in enumerate(nn_80) if x == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 0.8060124360359334 0.8034749512331564\n",
      "226 0.8091423666149207 0.8041590250378898\n",
      "227 0.817840144583328 0.8020445261640035\n",
      "231 0.8175716168845519 0.8003426939964753\n",
      "238 0.813947603532291 0.8003677624387309\n",
      "242 0.8137796100976988 0.8049583339147678\n",
      "246 0.8122114854816177 0.8000197750902687\n",
      "247 0.8162660962905429 0.8003746142318546\n",
      "255 0.810086174374483 0.8040305603512359\n",
      "259 0.8086534151355091 0.8030545575842853\n",
      "262 0.8150520976499078 0.805213234707088\n",
      "272 0.817337356480424 0.802185852047906\n",
      "277 0.8200640691796326 0.807585888052018\n",
      "287 0.8150293836071896 0.8040559253853065\n",
      "290 0.815890394346726 0.8072063929499491\n",
      "307 0.8096319979837174 0.8058570608859514\n",
      "309 0.8191694308125697 0.803345070994135\n",
      "321 0.8177367224176121 0.8046951907438333\n",
      "334 0.8230749673834418 0.8005533528872849\n",
      "339 0.8215469837289632 0.8008402443214917\n",
      "340 0.8155064301759346 0.8034185729290498\n",
      "353 0.7982863135957657 0.8004052167512239\n",
      "354 0.8019464351909215 0.800434533441908\n",
      "357 0.8169529820642533 0.8000940803436973\n",
      "363 0.8091189992147353 0.8024986817981957\n",
      "368 0.8206951434052138 0.8036152664901917\n",
      "369 0.8120073227574762 0.8014065497592054\n",
      "370 0.8143798298095591 0.8008666557177648\n",
      "373 0.8159916260460749 0.8036891800476821\n",
      "378 0.8192729197354106 0.8009513234656768\n",
      "381 0.8182414298752696 0.8057910884813921\n",
      "383 0.8164464839409392 0.8034378883464546\n",
      "385 0.8255585568186519 0.8072998963604314\n",
      "386 0.8242641662263628 0.8006901929022676\n",
      "392 0.8144075913075735 0.8036395097345697\n",
      "397 0.8090221576136964 0.8033267941662823\n",
      "400 0.8242934540007003 0.8026531017559705\n",
      "402 0.8165969503878501 0.8033400353528682\n",
      "403 0.824174729814556 0.8021181391335497\n",
      "407 0.8173248476091295 0.8010258733375416\n",
      "409 0.8202017762920186 0.8069073570675204\n",
      "416 0.8258455120248567 0.8021882869805772\n",
      "567 0.8029485760672519 0.8055868917662461\n",
      "569 0.8062587289862486 0.8020142883650406\n",
      "599 0.8165640235984372 0.8013400868903044\n",
      "601 0.8127174234442276 0.8017458945759925\n",
      "609 0.8153631044388583 0.8008253821744951\n",
      "615 0.8147557916917687 0.8014130836817088\n",
      "617 0.816299143077928 0.8020785984463582\n",
      "622 0.8121074054118914 0.8020062065989062\n",
      "628 0.809978757038123 0.8017366558166462\n",
      "631 0.8032165748185542 0.8009108398791305\n",
      "634 0.8005252127774788 0.8006507906976759\n",
      "643 0.8176712808929172 0.8013773542413621\n",
      "645 0.8226262681843387 0.8004258513600602\n",
      "646 0.8322221886801331 0.8045779000903225\n",
      "648 0.8323364254437111 0.8005198772859305\n",
      "671 0.8340937208364505 0.8015449539668689\n",
      "674 0.8354063558158769 0.80562878579883\n",
      "683 0.8320809165799852 0.8022006247810904\n",
      "684 0.8272733695809108 0.8003222710228853\n",
      "686 0.8345042759576187 0.807336654291605\n",
      "694 0.8319432674206486 0.8022453171329254\n",
      "699 0.8175708245217197 0.8001833916243251\n",
      "701 0.8092392551790706 0.8043715640355401\n",
      "719 0.839776792967923 0.8008136115612454\n",
      "720 0.8303086902775841 0.8039458482211514\n",
      "740 0.8412964893082379 0.8021433560179795\n",
      "748 0.8451944235960136 0.8018477868094336\n",
      "756 0.8407798123525372 0.8032362369652775\n",
      "770 0.8135579629439783 0.8090422121740877\n",
      "778 0.8429730559447548 0.808288777870112\n",
      "781 0.8427421961298512 0.800771244410144\n",
      "782 0.8340159599931408 0.8015177858538653\n",
      "783 0.833581414294132 0.8047466265653564\n",
      "785 0.8309698237694966 0.804047067886092\n",
      "790 0.8505578930808553 0.8009952711485158\n",
      "800 0.8470035055160958 0.800637712307825\n",
      "802 0.8435669344353545 0.8007038368604384\n",
      "836 0.845014460087564 0.8010493442227999\n",
      "946 0.8055980180159383 0.8022564565880415\n",
      "991 0.8134042224860358 0.8013763235459203\n",
      "1008 0.8291179937425551 0.801551175685502\n",
      "1017 0.8183684459138056 0.800124805745331\n",
      "1029 0.8266788929296702 0.8030272579963789\n",
      "1034 0.8298145537750501 0.8002165036989779\n",
      "1039 0.8313910484138878 0.8041172027004991\n",
      "1047 0.8334178812953582 0.802045205088646\n",
      "1050 0.8111877684799549 0.800855086034591\n",
      "1052 0.8122135624558489 0.8013071726207937\n",
      "1121 0.816076923672888 0.8041950123526392\n",
      "1126 0.8126836291742482 0.8022173880472397\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print (str(i+1),nn.iloc[:,i+1]['r2_train'],nn.iloc[:,i+1]['r2_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(models, orient='index').to_csv('nn_models_vRegL1_fullstats_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for different seeds in train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 1 \n",
      "Accuracy for training is: 0.8295780219401722 Accuracy for test is: 0.7862437470114041 \n",
      "MSE for training is: 110.81402596852958 MSE for test is: 149.69211466589633 \n",
      "MAE for training is: 6.97175548488227 MAE for test is: 7.7956463187765035 \n",
      "RMSE for training is: 10.526824115968195 RMSE for test is: 12.234872891284827\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 2 \n",
      "Accuracy for training is: 0.842974838869992 Accuracy for test is: 0.7836247452396453 \n",
      "MSE for training is: 101.02489015118717 MSE for test is: 157.5171612763641 \n",
      "MAE for training is: 6.759708829327572 MAE for test is: 7.700277419663239 \n",
      "RMSE for training is: 10.051113876142642 RMSE for test is: 12.55058410100359\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 3 \n",
      "Accuracy for training is: 0.8336917730479867 Accuracy for test is: 0.750582720890489 \n",
      "MSE for training is: 109.6723839003213 MSE for test is: 165.5521619517944 \n",
      "MAE for training is: 6.914823378615849 MAE for test is: 7.806074227669567 \n",
      "RMSE for training is: 10.47245835037415 RMSE for test is: 12.866707502379713\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 4 \n",
      "Accuracy for training is: 0.8159016879359453 Accuracy for test is: 0.7567865811203991 \n",
      "MSE for training is: 121.505361691088 MSE for test is: 160.89924386874918 \n",
      "MAE for training is: 7.52857133854577 MAE for test is: 8.108344236364193 \n",
      "RMSE for training is: 11.022947051087925 RMSE for test is: 12.684606571303235\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 5 \n",
      "Accuracy for training is: 0.8435278857257607 Accuracy for test is: 0.7797544143258448 \n",
      "MSE for training is: 105.01465289302745 MSE for test is: 135.84664972690445 \n",
      "MAE for training is: 6.864812860325402 MAE for test is: 7.620126117261795 \n",
      "RMSE for training is: 10.247665728985671 RMSE for test is: 11.655327096521335\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 6 \n",
      "Accuracy for training is: 0.8214881267089748 Accuracy for test is: 0.7961472482557821 \n",
      "MSE for training is: 118.38555940058004 MSE for test is: 132.26815703884742 \n",
      "MAE for training is: 7.197971385017697 MAE for test is: 7.466180606232494 \n",
      "RMSE for training is: 10.88051282801413 RMSE for test is: 11.500789409377402\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 7 \n",
      "Accuracy for training is: 0.8395260602691239 Accuracy for test is: 0.7702208053744145 \n",
      "MSE for training is: 104.0332990539874 MSE for test is: 162.7061932805375 \n",
      "MAE for training is: 6.945940991486842 MAE for test is: 7.899140291787823 \n",
      "RMSE for training is: 10.199671516965015 RMSE for test is: 12.75563378592132\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 8 \n",
      "Accuracy for training is: 0.8164195047658585 Accuracy for test is: 0.7779351231034696 \n",
      "MSE for training is: 121.38724055919221 MSE for test is: 145.81279467857723 \n",
      "MAE for training is: 7.159333704783331 MAE for test is: 7.759195533753135 \n",
      "RMSE for training is: 11.017587783139838 RMSE for test is: 12.075296877450974\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 9 \n",
      "Accuracy for training is: 0.8457444083286672 Accuracy for test is: 0.7729920917621349 \n",
      "MSE for training is: 103.5676286187841 MSE for test is: 139.77715277272256 \n",
      "MAE for training is: 6.785648680235968 MAE for test is: 7.404590769101871 \n",
      "RMSE for training is: 10.17681819719622 RMSE for test is: 11.822738801678845\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 10 \n",
      "Accuracy for training is: 0.8389552389742895 Accuracy for test is: 0.7745743547712471 \n",
      "MSE for training is: 105.58765320482465 MSE for test is: 153.0401568994014 \n",
      "MAE for training is: 6.710865403930604 MAE for test is: 7.710727473229326 \n",
      "RMSE for training is: 10.275585297433166 RMSE for test is: 12.370940016805571\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 11 \n",
      "Accuracy for training is: 0.8273005294095183 Accuracy for test is: 0.7669544592713209 \n",
      "MSE for training is: 113.63895371460092 MSE for test is: 156.02482100338355 \n",
      "MAE for training is: 7.053506883207118 MAE for test is: 7.772028153694623 \n",
      "RMSE for training is: 10.660157302526118 RMSE for test is: 12.490989592637709\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 12 \n",
      "Accuracy for training is: 0.8368465302469197 Accuracy for test is: 0.782383455632002 \n",
      "MSE for training is: 109.289418904685 MSE for test is: 135.3310049168616 \n",
      "MAE for training is: 7.08601811495197 MAE for test is: 7.7485817593129145 \n",
      "RMSE for training is: 10.454157972055185 RMSE for test is: 11.633185501695637\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 13 \n",
      "Accuracy for training is: 0.8349122895533452 Accuracy for test is: 0.8015068943331902 \n",
      "MSE for training is: 108.99108021321132 MSE for test is: 131.14856940085292 \n",
      "MAE for training is: 6.916586938093462 MAE for test is: 7.544448882354171 \n",
      "RMSE for training is: 10.439879319858603 RMSE for test is: 11.45201158752701\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 14 \n",
      "Accuracy for training is: 0.8351524317859041 Accuracy for test is: 0.7791359695853308 \n",
      "MSE for training is: 109.81188580528577 MSE for test is: 140.67932436618972 \n",
      "MAE for training is: 6.976605333055933 MAE for test is: 7.6121091539308035 \n",
      "RMSE for training is: 10.479116651955248 RMSE for test is: 11.860831520858465\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 15 \n",
      "Accuracy for training is: 0.8428128512846272 Accuracy for test is: 0.7803671833968739 \n",
      "MSE for training is: 102.75002296182899 MSE for test is: 150.8427071140512 \n",
      "MAE for training is: 6.911323980475147 MAE for test is: 7.70904557860693 \n",
      "RMSE for training is: 10.13656859898008 RMSE for test is: 12.281803903093845\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 16 \n",
      "Accuracy for training is: 0.8241058520714941 Accuracy for test is: 0.7641839112929466 \n",
      "MSE for training is: 116.27694555859445 MSE for test is: 155.0035567886141 \n",
      "MAE for training is: 7.080377414740147 MAE for test is: 7.706946801355764 \n",
      "RMSE for training is: 10.783178824381725 RMSE for test is: 12.450042441237464\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 17 \n",
      "Accuracy for training is: 0.8233215592722101 Accuracy for test is: 0.7976921666465876 \n",
      "MSE for training is: 115.15051769770143 MSE for test is: 140.50845904533702 \n",
      "MAE for training is: 7.009292953513358 MAE for test is: 7.604249398543735 \n",
      "RMSE for training is: 10.730820923755156 RMSE for test is: 11.853626409050397\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 18 \n",
      "Accuracy for training is: 0.8303463918786275 Accuracy for test is: 0.7933745635540569 \n",
      "MSE for training is: 111.0479904712073 MSE for test is: 141.13907548105058 \n",
      "MAE for training is: 7.086514530710257 MAE for test is: 7.664326163475523 \n",
      "RMSE for training is: 10.537931033709004 RMSE for test is: 11.880196777875803\n",
      "\n",
      "*For model 790 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.01 -random_state: 19 \n",
      "Accuracy for training is: 0.8369013863337305 Accuracy for test is: 0.764938199316349 \n",
      "MSE for training is: 107.69935704486053 MSE for test is: 155.18703559863474 \n",
      "MAE for training is: 6.9386129929046225 MAE for test is: 7.683260612356036 \n",
      "RMSE for training is: 10.37783007400201 RMSE for test is: 12.457408863749906\n"
     ]
    }
   ],
   "source": [
    "i = 789\n",
    "nh = int(nn.iloc[:,i+1]['hidden_neurons'])\n",
    "hl = int(nn.iloc[:,i+1]['hidden_layers'])\n",
    "e = int(nn.iloc[:,i+1]['epochs'])\n",
    "a = nn.iloc[:,i+1]['activation']\n",
    "\n",
    "models = {}\n",
    "r = 0.01\n",
    "\n",
    "rndm = [x for x in range(1, 101)]\n",
    "\n",
    "for rnd in rndm:\n",
    "    \n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2, random_state=rnd) #split\n",
    "    \n",
    "    model = neuron_layers(10,nh,1,hl,a,r)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "    #statistics for train\n",
    "    y_hat= model.predict(X_train)\n",
    "    acc_train = r2_score(Y_train, y_hat)\n",
    "    mse_train = mean_squared_error(Y_train, y_hat)\n",
    "    mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "    rmse_train = mean_squared_error(Y_train, y_hat, squared=False)    \n",
    "\n",
    "    #accuracy for test\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc_test = r2_score(Y_test, y_hat)\n",
    "    mse_test = mean_squared_error(Y_test, y_hat)\n",
    "    mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "    rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "    models['model'+str(i+1)+'-'+str(r)] = [e, nh, hl, a, r, rnd, acc_train, mse_train, mae_train, rmse_train, acc_test, mse_test, mae_test, rmse_test]\n",
    "\n",
    "    print ('\\n*For model',str(i+1),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "           '-regularization cost:',r,'-random_state:',rnd,\n",
    "           '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test),\n",
    "          '\\nMSE for training is:', str(mse_train),'MSE for test is:',str(mse_test),\n",
    "           '\\nMAE for training is:', str(mae_train),'MAE for test is:',str(mae_test),\n",
    "           '\\nRMSE for training is:', str(rmse_train),'RMSE for test is:',str(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
