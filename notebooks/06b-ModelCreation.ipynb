{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27504, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FECHA   HORA PARAM    AGU     ATM     CEN     LDO  LPIN  \\\n",
       "4   2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04  -1.0   \n",
       "13  2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27  -1.0   \n",
       "22  2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00  -1.0   \n",
       "31  2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65  -1.0   \n",
       "40  2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70  -1.0   \n",
       "\n",
       "       MIR     OBL     SFE     TLA    VAL  \n",
       "4    69.75  197.67  115.54  143.40  17.08  \n",
       "13   68.99  138.09   84.24  100.46  29.15  \n",
       "22  117.70   98.79  135.39   82.05  30.89  \n",
       "31  160.30   97.94  117.60  114.74  38.74  \n",
       "40  180.89  134.39  164.68  118.83  51.48  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.CEN != -1] #Elimina valores negativos en la columna de salida\n",
    "print(df_data.shape)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer='normal', activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ls = [50, 100, 200] #50 y 100, 250\n",
    "nh_ls = [5,10,25,50,75,100] #minimo 5, maximo 25 de una en una (8-18)\n",
    "hl_ls = [1,2,3,4,5,6,7,8,9,10] #maximo 3 capas\n",
    "reg_ls = [1,0.75,0.5,0.1,0.05,0.01,0.005]\n",
    "activation_ls = ['relu'] #relu\n",
    "\n",
    "models = {}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for e in epochs_ls:\n",
    "        for nh in nh_ls:\n",
    "            for hl in hl_ls:\n",
    "                for r in reg_ls:\n",
    "                    for a in activation_ls:\n",
    "                    \n",
    "                        model = neuron_layers(10,nh,1,hl,a,r)\n",
    "\n",
    "                        model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "                        history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "                        #statistics for train\n",
    "                        y_hat= model.predict(X_train)\n",
    "                        acc_train = r2_score(Y_train, y_hat)\n",
    "                        mse_train = mean_squared_error(Y_train, y_hat)\n",
    "                        mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "                        rmse_train = mean_squared_error(Y_train, y_hat, squared=False)\n",
    "\n",
    "                        res_train = Y_train - y_hat\n",
    "                        std_res_train = round(res_train.std(),3)\n",
    "\n",
    "                        num_train = ((y_hat - Y_train)**2).sum()\n",
    "                        den_train = ((abs(y_hat - Y_train.mean()) + \n",
    "                                abs(Y_train - Y_train.mean()))**2).sum()\n",
    "                        ia_train = round(1 - (num_train / den_train),3)\n",
    "\n",
    "                        #accuracy for test\n",
    "                        y_hat = model.predict(X_test)\n",
    "                        acc_test = r2_score(Y_test, y_hat)\n",
    "                        mse_test = mean_squared_error(Y_test, y_hat)\n",
    "                        mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "                        rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "                        res_test = Y_test - y_hat\n",
    "                        std_res_test = round(res_test.std(),3)\n",
    "\n",
    "                        num_test = ((y_hat - Y_test)**2).sum()\n",
    "                        den_test = ((abs(y_hat - Y_test.mean()) + \n",
    "                                abs(Y_test - Y_test.mean()))**2).sum()\n",
    "                        ia_test = round(1 - (num_test / den_test),3)\n",
    "\n",
    "                        models['model'+str(i+1)+'-'+str(r)] = [e, nh, hl, a, r, \n",
    "                                                               acc_train, mse_train, mae_train, rmse_train, std_res_train, ia_train\n",
    "                                                               acc_test, mse_test, mae_test, rmse_test, std_res_test, ia_test]\n",
    "\n",
    "                        print ('\\n*For model',str(i+1),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "                               '-regularization cost:',r,\n",
    "                               '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(models)\n",
    "df_models.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = df_models.set_index('Unnamed: 0').transpose()\n",
    "print(df_models.shape)\n",
    "df_models.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.to_csv('../output/data/nn_models_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.acc_train.idxmax()\n",
    "df_models.mse_train.idxmin()\n",
    "df_models.mae_train.idxmin()\n",
    "df_models.rmse_train.idxmin()\n",
    "df_models.std_res_train.idxmin()\n",
    "df_models.ia_train.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.acc_test.idxmax()\n",
    "df_models.mse_test.idxmin()\n",
    "df_models.mae_test.idxmin()\n",
    "df_models.rmse_test.idxmin()\n",
    "df_models.std_res_test.idxmin()\n",
    "df_models.ia_test.idxmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
