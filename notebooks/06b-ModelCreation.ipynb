{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9709, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FECHA   HORA PARAM    AGU     ATM     CEN     LDO  LPIN  \\\n",
       "4   2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04  -1.0   \n",
       "13  2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27  -1.0   \n",
       "22  2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00  -1.0   \n",
       "31  2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65  -1.0   \n",
       "40  2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70  -1.0   \n",
       "\n",
       "       MIR     OBL     SFE     TLA    VAL  \n",
       "4    69.75  197.67  115.54  143.40  17.08  \n",
       "13   68.99  138.09   84.24  100.46  29.15  \n",
       "22  117.70   98.79  135.39   82.05  30.89  \n",
       "31  160.30   97.94  117.60  114.74  38.74  \n",
       "40  180.89  134.39  164.68  118.83  51.48  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.AGU != -1] #Elimina valores negativos en la columna de salida\n",
    "print(df_data.shape)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['CEN','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"AGU\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r, seed=None):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    initializer = tf.keras.initializers.RandomNormal(seed=seed)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer=initializer,\n",
    "                            activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*For model 1 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6788056019297781 Accuracy for test is: 0.7078830886669805\n",
      "\n",
      "*For model 2 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6733754275474879 Accuracy for test is: 0.6971806266470155\n",
      "\n",
      "*For model 3 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6350214236220189 Accuracy for test is: 0.6538122513851675\n",
      "\n",
      "*For model 4 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6691990228185392 Accuracy for test is: 0.6895876342228767\n",
      "\n",
      "*For model 5 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6639760224770318 Accuracy for test is: 0.6860475872635463\n",
      "\n",
      "*For model 6 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6701060014492611 Accuracy for test is: 0.6921428508007833\n",
      "\n",
      "*For model 7 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 1 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6303501061444436 Accuracy for test is: 0.6560565903316902\n",
      "\n",
      "*For model 8 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6727986994254483 Accuracy for test is: 0.7046719154963283\n",
      "\n",
      "*For model 9 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6736676155034413 Accuracy for test is: 0.695644631926391\n",
      "\n",
      "*For model 10 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6769932512145094 Accuracy for test is: 0.7106070684675134\n",
      "\n",
      "*For model 11 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6426015723604084 Accuracy for test is: 0.6515104658605401\n",
      "\n",
      "*For model 12 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6306011845939845 Accuracy for test is: 0.6500155214799023\n",
      "\n",
      "*For model 13 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6371155138526479 Accuracy for test is: 0.6622495932738188\n",
      "\n",
      "*For model 14 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 2 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6804121350841461 Accuracy for test is: 0.7063775879122753\n",
      "\n",
      "*For model 15 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.674303644846431 Accuracy for test is: 0.6985440863801262\n",
      "\n",
      "*For model 16 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: -1.7356429240504707 Accuracy for test is: -1.6200105888512253\n",
      "\n",
      "*For model 17 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6437979234810864 Accuracy for test is: 0.664205577890182\n",
      "\n",
      "*For model 18 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6307425967340872 Accuracy for test is: 0.6568891817946058\n",
      "\n",
      "*For model 19 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6591088616327602 Accuracy for test is: 0.6828813358494576\n",
      "\n",
      "*For model 20 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6714513951716405 Accuracy for test is: 0.6989646039889349\n",
      "\n",
      "*For model 21 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 3 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6824359497810542 Accuracy for test is: 0.6984846313976927\n",
      "\n",
      "*For model 22 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6909336932512251 Accuracy for test is: 0.7114208769991475\n",
      "\n",
      "*For model 23 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6804449023160865 Accuracy for test is: 0.7062370509630898\n",
      "\n",
      "*For model 24 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6663255761588815 Accuracy for test is: 0.6964327453554915\n",
      "\n",
      "*For model 25 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6474387345076994 Accuracy for test is: 0.6667252855273836\n",
      "\n",
      "*For model 26 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6153963864870633 Accuracy for test is: 0.6428790718375206\n",
      "\n",
      "*For model 27 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6599054901495529 Accuracy for test is: 0.664821831588788\n",
      "\n",
      "*For model 28 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 4 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6738580885827024 Accuracy for test is: 0.7009760629763995\n",
      "\n",
      "*For model 29 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6365539599662364 Accuracy for test is: 0.6534711499385151\n",
      "\n",
      "*For model 30 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6512192903121126 Accuracy for test is: 0.6698228120717707\n",
      "\n",
      "*For model 31 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6738293297300201 Accuracy for test is: 0.6990536068633183\n",
      "\n",
      "*For model 32 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.644727273933147 Accuracy for test is: 0.6618365619403205\n",
      "\n",
      "*For model 33 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6092136555846335 Accuracy for test is: 0.6345518687405122\n",
      "\n",
      "*For model 34 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6528925366586986 Accuracy for test is: 0.6677590350065604\n",
      "\n",
      "*For model 35 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 5 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6712313621336965 Accuracy for test is: 0.7003121633073555\n",
      "\n",
      "*For model 36 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6408234984943167 Accuracy for test is: 0.6664226725791349\n",
      "\n",
      "*For model 37 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: -1.734839762258996 Accuracy for test is: -1.619180069074785\n",
      "\n",
      "*For model 38 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6622667429491864 Accuracy for test is: 0.6733899952697233\n",
      "\n",
      "*For model 39 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6319562532321771 Accuracy for test is: 0.6532009359645994\n",
      "\n",
      "*For model 40 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6479448396047526 Accuracy for test is: 0.6589416001699782\n",
      "\n",
      "*For model 41 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6785407349905959 Accuracy for test is: 0.6944396388646923\n",
      "\n",
      "*For model 42 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 6 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6743293461456208 Accuracy for test is: 0.7029333439634156\n",
      "\n",
      "*For model 43 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6537271874890864 Accuracy for test is: 0.6568894852375926\n",
      "\n",
      "*For model 44 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.655810390469779 Accuracy for test is: 0.6729111103023373\n",
      "\n",
      "*For model 45 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6773777729995101 Accuracy for test is: 0.7038489648986858\n",
      "\n",
      "*For model 46 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6663670549798824 Accuracy for test is: 0.6830790051476089\n",
      "\n",
      "*For model 47 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6425763303744001 Accuracy for test is: 0.6658212521879097\n",
      "\n",
      "*For model 48 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6643262425876262 Accuracy for test is: 0.6814241376374827\n",
      "\n",
      "*For model 49 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 7 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6680432571138062 Accuracy for test is: 0.6970988616085632\n",
      "\n",
      "*For model 50 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6708334916950788 Accuracy for test is: 0.6918843778303314\n",
      "\n",
      "*For model 51 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6609913086372491 Accuracy for test is: 0.6784578686995095\n",
      "\n",
      "*For model 52 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.669858369646945 Accuracy for test is: 0.6943587895795502\n",
      "\n",
      "*For model 53 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: -0.00016617780640104662 Accuracy for test is: -0.000855184391863606\n",
      "\n",
      "*For model 54 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6685788737480454 Accuracy for test is: 0.6836041430710551\n",
      "\n",
      "*For model 55 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6695618851999021 Accuracy for test is: 0.7004775679027624\n",
      "\n",
      "*For model 56 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 8 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: -1.7347940420466839 Accuracy for test is: -1.6191359848465963\n",
      "\n",
      "*For model 57 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6347227992761801 Accuracy for test is: 0.658162073734859\n",
      "\n",
      "*For model 58 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6181758267241853 Accuracy for test is: 0.6433309854819624\n",
      "\n",
      "*For model 59 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6556821801050016 Accuracy for test is: 0.6818530025955334\n",
      "\n",
      "*For model 60 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6267114658126507 Accuracy for test is: 0.653250212958385\n",
      "\n",
      "*For model 61 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6298395124695859 Accuracy for test is: 0.6555136825228779\n",
      "\n",
      "*For model 62 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6408799652392976 Accuracy for test is: 0.6612337384693145\n",
      "\n",
      "*For model 63 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 9 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: -1.7348290563701378 Accuracy for test is: -1.6191697462678172\n",
      "\n",
      "*For model 64 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6302116263540642 Accuracy for test is: 0.6488987785218111\n",
      "\n",
      "*For model 65 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6697226128328907 Accuracy for test is: 0.69021602446322\n",
      "\n",
      "*For model 66 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6712410472713635 Accuracy for test is: 0.6859884653846173\n",
      "\n",
      "*For model 67 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6619268813829629 Accuracy for test is: 0.6882675106274074\n",
      "\n",
      "*For model 68 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: -3.9110089715466145e-05 Accuracy for test is: -0.001286503332699196\n",
      "\n",
      "*For model 69 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6598383630923572 Accuracy for test is: 0.6863148086058213\n",
      "\n",
      "*For model 70 settings are: -epochs: 50 -hidden neurons: 5 -hidden layers: 10 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6841384620739015 Accuracy for test is: 0.7000064862983282\n",
      "\n",
      "*For model 71 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6745655155263528 Accuracy for test is: 0.7000988911716037\n",
      "\n",
      "*For model 72 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.678293181074878 Accuracy for test is: 0.7031747025660384\n",
      "\n",
      "*For model 73 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6482237548963207 Accuracy for test is: 0.6779890021055266\n",
      "\n",
      "*For model 74 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6770950491853536 Accuracy for test is: 0.6997981774473404\n",
      "\n",
      "*For model 75 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6665715726570092 Accuracy for test is: 0.6872570558215054\n",
      "\n",
      "*For model 76 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6733784206004497 Accuracy for test is: 0.6995236744056159\n",
      "\n",
      "*For model 77 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 1 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6670979389630605 Accuracy for test is: 0.692933637156822\n",
      "\n",
      "*For model 78 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6806324118068461 Accuracy for test is: 0.7097710104219637\n",
      "\n",
      "*For model 79 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6774270117063563 Accuracy for test is: 0.6911862822759411\n",
      "\n",
      "*For model 80 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.689979476700858 Accuracy for test is: 0.7044776348529365\n",
      "\n",
      "*For model 81 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6740512600100197 Accuracy for test is: 0.7037338434304499\n",
      "\n",
      "*For model 82 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6689285134619444 Accuracy for test is: 0.6880110065685214\n",
      "\n",
      "*For model 83 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6739367598749797 Accuracy for test is: 0.6862332552454851\n",
      "\n",
      "*For model 84 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 2 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6835766936470131 Accuracy for test is: 0.7123353487427342\n",
      "\n",
      "*For model 85 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6616387631585113 Accuracy for test is: 0.6933213612096003\n",
      "\n",
      "*For model 86 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6786362356698038 Accuracy for test is: 0.7024224291374841\n",
      "\n",
      "*For model 87 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6680358048798557 Accuracy for test is: 0.6853551760952443\n",
      "\n",
      "*For model 88 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6889966118857075 Accuracy for test is: 0.7113891369668224\n",
      "\n",
      "*For model 89 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6832773538373622 Accuracy for test is: 0.7031608593895455\n",
      "\n",
      "*For model 90 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6754155286808488 Accuracy for test is: 0.6957913494674286\n",
      "\n",
      "*For model 91 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 3 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6711855966417819 Accuracy for test is: 0.6908042402511245\n",
      "\n",
      "*For model 92 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6758475359679323 Accuracy for test is: 0.7014279540906401\n",
      "\n",
      "*For model 93 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6478214430123983 Accuracy for test is: 0.6644180716941227\n",
      "\n",
      "*For model 94 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6776399354762346 Accuracy for test is: 0.6986359771170844\n",
      "\n",
      "*For model 95 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6498911602368538 Accuracy for test is: 0.6577900879227543\n",
      "\n",
      "*For model 96 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6722393541330092 Accuracy for test is: 0.685968832981213\n",
      "\n",
      "*For model 97 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6771957717908976 Accuracy for test is: 0.6894068494814367\n",
      "\n",
      "*For model 98 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 4 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6821973884553048 Accuracy for test is: 0.696608389848991\n",
      "\n",
      "*For model 99 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6775989244400797 Accuracy for test is: 0.7020843811018411\n",
      "\n",
      "*For model 100 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6743974575743088 Accuracy for test is: 0.6945272288340865\n",
      "\n",
      "*For model 101 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6843315474237773 Accuracy for test is: 0.7079084160345231\n",
      "\n",
      "*For model 102 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6231756907230621 Accuracy for test is: 0.6573303896508035\n",
      "\n",
      "*For model 103 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6584609123703924 Accuracy for test is: 0.6758543798301822\n",
      "\n",
      "*For model 104 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6862205177289915 Accuracy for test is: 0.7103297996138921\n",
      "\n",
      "*For model 105 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 5 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6948766327244907 Accuracy for test is: 0.7108466034565708\n",
      "\n",
      "*For model 106 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6732109460763895 Accuracy for test is: 0.6957227605685501\n",
      "\n",
      "*For model 107 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6800867762948435 Accuracy for test is: 0.7023439037516803\n",
      "\n",
      "*For model 108 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.682215911867969 Accuracy for test is: 0.6979877052610265\n",
      "\n",
      "*For model 109 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6751178633858435 Accuracy for test is: 0.7004240922225986\n",
      "\n",
      "*For model 110 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6923517743126446 Accuracy for test is: 0.719725107856221\n",
      "\n",
      "*For model 111 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6801380402598454 Accuracy for test is: 0.6905516712066019\n",
      "\n",
      "*For model 112 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 6 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6742068162956578 Accuracy for test is: 0.6915949267605142\n",
      "\n",
      "*For model 113 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6841367273758747 Accuracy for test is: 0.6922122418813991\n",
      "\n",
      "*For model 114 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6585382499938512 Accuracy for test is: 0.6892646468611898\n",
      "\n",
      "*For model 115 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6742230214128884 Accuracy for test is: 0.70001475621516\n",
      "\n",
      "*For model 116 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6871738648136582 Accuracy for test is: 0.6965810357323401\n",
      "\n",
      "*For model 117 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6702192953904611 Accuracy for test is: 0.694346673086051\n",
      "\n",
      "*For model 118 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6923718975701858 Accuracy for test is: 0.7015861755607703\n",
      "\n",
      "*For model 119 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 7 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.683402949925058 Accuracy for test is: 0.6914167555484698\n",
      "\n",
      "*For model 120 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6719923686150996 Accuracy for test is: 0.6911563595800743\n",
      "\n",
      "*For model 121 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6845487572872794 Accuracy for test is: 0.7064312245983516\n",
      "\n",
      "*For model 122 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6777136980994529 Accuracy for test is: 0.6909426777125562\n",
      "\n",
      "*For model 123 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.681745833150232 Accuracy for test is: 0.6970191358320639\n",
      "\n",
      "*For model 124 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6731763969664674 Accuracy for test is: 0.6895324887603504\n",
      "\n",
      "*For model 125 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6589991197820407 Accuracy for test is: 0.6702473532262085\n",
      "\n",
      "*For model 126 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 8 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6812033950091541 Accuracy for test is: 0.6990231514276\n",
      "\n",
      "*For model 127 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6512505937346269 Accuracy for test is: 0.6683480342314393\n",
      "\n",
      "*For model 128 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.673244651775162 Accuracy for test is: 0.6936416784113905\n",
      "\n",
      "*For model 129 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6850796459993566 Accuracy for test is: 0.7145656876172881\n",
      "\n",
      "*For model 130 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6826848975039543 Accuracy for test is: 0.7037247144808594\n",
      "\n",
      "*For model 131 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6746923926359605 Accuracy for test is: 0.6959336943118429\n",
      "\n",
      "*For model 132 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6867908935187554 Accuracy for test is: 0.7016968357489237\n",
      "\n",
      "*For model 133 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 9 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6908458051441204 Accuracy for test is: 0.7021719430911197\n",
      "\n",
      "*For model 134 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6901384699223605 Accuracy for test is: 0.7045389174663814\n",
      "\n",
      "*For model 135 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6837146232959378 Accuracy for test is: 0.7050721317623123\n",
      "\n",
      "*For model 136 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6789357074370339 Accuracy for test is: 0.6844425253280337\n",
      "\n",
      "*For model 137 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6602116002835116 Accuracy for test is: 0.6748695721683575\n",
      "\n",
      "*For model 138 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.68075409430986 Accuracy for test is: 0.7055812595372646\n",
      "\n",
      "*For model 139 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6699867582066985 Accuracy for test is: 0.6932012071285718\n",
      "\n",
      "*For model 140 settings are: -epochs: 50 -hidden neurons: 10 -hidden layers: 10 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6789207012635978 Accuracy for test is: 0.7061947386409118\n",
      "\n",
      "*For model 141 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6784822701095392 Accuracy for test is: 0.6948598087079897\n",
      "\n",
      "*For model 142 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.66218473039575 Accuracy for test is: 0.692197118561588\n",
      "\n",
      "*For model 143 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6791191054416764 Accuracy for test is: 0.6816741418741488\n",
      "\n",
      "*For model 144 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6496203881759244 Accuracy for test is: 0.6668936001323349\n",
      "\n",
      "*For model 145 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6553307190238455 Accuracy for test is: 0.6857392988479651\n",
      "\n",
      "*For model 146 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6839496896766695 Accuracy for test is: 0.6975805792556127\n",
      "\n",
      "*For model 147 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 1 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6771143849666776 Accuracy for test is: 0.6930462495602532\n",
      "\n",
      "*For model 148 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6964970306280811 Accuracy for test is: 0.6993729231129351\n",
      "\n",
      "*For model 149 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7054275609819991 Accuracy for test is: 0.7174789835142613\n",
      "\n",
      "*For model 150 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7009969795687159 Accuracy for test is: 0.7156107483835061\n",
      "\n",
      "*For model 151 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6982727055108577 Accuracy for test is: 0.7079046835110727\n",
      "\n",
      "*For model 152 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6925356993778066 Accuracy for test is: 0.7046835964304922\n",
      "\n",
      "*For model 153 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6980209521811298 Accuracy for test is: 0.7112874612520752\n",
      "\n",
      "*For model 154 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 2 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7088333856172695 Accuracy for test is: 0.7082211735360036\n",
      "\n",
      "*For model 155 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.7178673785470003 Accuracy for test is: 0.7142922138940524\n",
      "\n",
      "*For model 156 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6894460583371451 Accuracy for test is: 0.706124266174575\n",
      "\n",
      "*For model 157 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7095864806115125 Accuracy for test is: 0.7080325361954203\n",
      "\n",
      "*For model 158 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6995722606125239 Accuracy for test is: 0.7140460302791196\n",
      "\n",
      "*For model 159 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6825639967842014 Accuracy for test is: 0.6924856770544814\n",
      "\n",
      "*For model 160 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7026892496890862 Accuracy for test is: 0.7121288188028541\n",
      "\n",
      "*For model 161 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 3 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7138783764623096 Accuracy for test is: 0.709617097749212\n",
      "\n",
      "*For model 162 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.715788347078761 Accuracy for test is: 0.7229684975609789\n",
      "\n",
      "*For model 163 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7045585476463511 Accuracy for test is: 0.7048351884882487\n",
      "\n",
      "*For model 164 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7132469932567544 Accuracy for test is: 0.7115475125015003\n",
      "\n",
      "*For model 165 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.718391181272316 Accuracy for test is: 0.7050041518984833\n",
      "\n",
      "*For model 166 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7119442258876781 Accuracy for test is: 0.6978700864194252\n",
      "\n",
      "*For model 167 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7056261692652426 Accuracy for test is: 0.7041006958886895\n",
      "\n",
      "*For model 168 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 4 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7098658959113927 Accuracy for test is: 0.710369214159703\n",
      "\n",
      "*For model 169 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.705798461278387 Accuracy for test is: 0.7048514948013298\n",
      "\n",
      "*For model 170 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6913506198052292 Accuracy for test is: 0.6925176215987977\n",
      "\n",
      "*For model 171 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.697114638219508 Accuracy for test is: 0.707518292052186\n",
      "\n",
      "*For model 172 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7082343600841292 Accuracy for test is: 0.7071451424740715\n",
      "\n",
      "*For model 173 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7121971756690666 Accuracy for test is: 0.6917086051391794\n",
      "\n",
      "*For model 174 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6925529004608475 Accuracy for test is: 0.6877802453897822\n",
      "\n",
      "*For model 175 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 5 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6972338190598151 Accuracy for test is: 0.7058355317822419\n",
      "\n",
      "*For model 176 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.7150452639075306 Accuracy for test is: 0.7134700828671878\n",
      "\n",
      "*For model 177 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7042232485052267 Accuracy for test is: 0.7076567746394886\n",
      "\n",
      "*For model 178 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7185793852615265 Accuracy for test is: 0.697492692111797\n",
      "\n",
      "*For model 179 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.705857751316338 Accuracy for test is: 0.7035085144332143\n",
      "\n",
      "*For model 180 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6971732951541552 Accuracy for test is: 0.7111867930659357\n",
      "\n",
      "*For model 181 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6966842230164435 Accuracy for test is: 0.7186760404134055\n",
      "\n",
      "*For model 182 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 6 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7073799264759297 Accuracy for test is: 0.7051370407057047\n",
      "\n",
      "*For model 183 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.7090309586232262 Accuracy for test is: 0.7148439543435452\n",
      "\n",
      "*For model 184 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.715644736497782 Accuracy for test is: 0.7014818461692665\n",
      "\n",
      "*For model 185 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7077530252321897 Accuracy for test is: 0.697902649792\n",
      "\n",
      "*For model 186 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6966174382288968 Accuracy for test is: 0.6864230324658604\n",
      "\n",
      "*For model 187 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7098015468697696 Accuracy for test is: 0.7183185366523216\n",
      "\n",
      "*For model 188 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6937780022201319 Accuracy for test is: 0.6894635125422175\n",
      "\n",
      "*For model 189 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 7 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6983973492512552 Accuracy for test is: 0.6960438747348442\n",
      "\n",
      "*For model 190 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6878691705815076 Accuracy for test is: 0.6873172778404559\n",
      "\n",
      "*For model 191 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6653918734161339 Accuracy for test is: 0.6576867509735822\n",
      "\n",
      "*For model 192 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6843059585010776 Accuracy for test is: 0.694025815810071\n",
      "\n",
      "*For model 193 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7162122821276212 Accuracy for test is: 0.7061402545124082\n",
      "\n",
      "*For model 194 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7073726427515616 Accuracy for test is: 0.7053206838908226\n",
      "\n",
      "*For model 195 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7052247602321522 Accuracy for test is: 0.7123516307245066\n",
      "\n",
      "*For model 196 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 8 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6842799777140391 Accuracy for test is: 0.6831259823855085\n",
      "\n",
      "*For model 197 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.711361888835225 Accuracy for test is: 0.7018291760137529\n",
      "\n",
      "*For model 198 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7192511991944761 Accuracy for test is: 0.6914296225641201\n",
      "\n",
      "*For model 199 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6986301436369512 Accuracy for test is: 0.6951193766406769\n",
      "\n",
      "*For model 200 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7150027897442274 Accuracy for test is: 0.7161769607596729\n",
      "\n",
      "*For model 201 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7162004896541871 Accuracy for test is: 0.7106969065284476\n",
      "\n",
      "*For model 202 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7197505639155422 Accuracy for test is: 0.7137693229233525\n",
      "\n",
      "*For model 203 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 9 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7062578487701595 Accuracy for test is: 0.7005566481506252\n",
      "\n",
      "*For model 204 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6850932679418289 Accuracy for test is: 0.6788536046275051\n",
      "\n",
      "*For model 205 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7164764414234391 Accuracy for test is: 0.702510841583186\n",
      "\n",
      "*For model 206 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7061444859086761 Accuracy for test is: 0.7099461251394257\n",
      "\n",
      "*For model 207 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6504438882386998 Accuracy for test is: 0.6465397307757449\n",
      "\n",
      "*For model 208 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7217510017157089 Accuracy for test is: 0.7283887858628797\n",
      "\n",
      "*For model 209 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7097882827312954 Accuracy for test is: 0.7147456810732198\n",
      "\n",
      "*For model 210 settings are: -epochs: 50 -hidden neurons: 25 -hidden layers: 10 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7075027747332618 Accuracy for test is: 0.7020660222885401\n",
      "\n",
      "*For model 211 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6779514733338196 Accuracy for test is: 0.6977515157971863\n",
      "\n",
      "*For model 212 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6820262098700194 Accuracy for test is: 0.700043002076018\n",
      "\n",
      "*For model 213 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.6891575995613419 Accuracy for test is: 0.7176847072455921\n",
      "\n",
      "*For model 214 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.6907723744444048 Accuracy for test is: 0.7119973976999836\n",
      "\n",
      "*For model 215 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.691589216684084 Accuracy for test is: 0.7064694847823831\n",
      "\n",
      "*For model 216 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.6956770916211329 Accuracy for test is: 0.7106020310772418\n",
      "\n",
      "*For model 217 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 1 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.6820515189661842 Accuracy for test is: 0.6993522054590885\n",
      "\n",
      "*For model 218 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.6775452849130179 Accuracy for test is: 0.6943071621887117\n",
      "\n",
      "*For model 219 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7039808703947004 Accuracy for test is: 0.7159417965676438\n",
      "\n",
      "*For model 220 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.71301650783322 Accuracy for test is: 0.7031710602192707\n",
      "\n",
      "*For model 221 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7090987471407746 Accuracy for test is: 0.7044294149374043\n",
      "\n",
      "*For model 222 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.7012102765296564 Accuracy for test is: 0.6999793377275834\n",
      "\n",
      "*For model 223 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.716051229361705 Accuracy for test is: 0.7183705767459136\n",
      "\n",
      "*For model 224 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 2 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.713167757559781 Accuracy for test is: 0.7102501905038299\n",
      "\n",
      "*For model 225 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.7313841621763768 Accuracy for test is: 0.7209538108401539\n",
      "\n",
      "*For model 226 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.7298997395044047 Accuracy for test is: 0.7033807624672661\n",
      "\n",
      "*For model 227 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.705545102430322 Accuracy for test is: 0.7081141449194404\n",
      "\n",
      "*For model 228 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7057827804644212 Accuracy for test is: 0.7249646434889641\n",
      "\n",
      "*For model 229 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.6741958706254096 Accuracy for test is: 0.6740802438960836\n",
      "\n",
      "*For model 230 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.01 \n",
      "Accuracy for training is: 0.7053926545345202 Accuracy for test is: 0.6908892185494389\n",
      "\n",
      "*For model 231 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 3 -activation: relu -regularization cost: 0.005 \n",
      "Accuracy for training is: 0.7269262560611367 Accuracy for test is: 0.7082304846868133\n",
      "\n",
      "*For model 232 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 4 -activation: relu -regularization cost: 1 \n",
      "Accuracy for training is: 0.7253067063943344 Accuracy for test is: 0.7196491198861767\n",
      "\n",
      "*For model 233 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 4 -activation: relu -regularization cost: 0.75 \n",
      "Accuracy for training is: 0.6983714800588026 Accuracy for test is: 0.6773884961323373\n",
      "\n",
      "*For model 234 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 4 -activation: relu -regularization cost: 0.5 \n",
      "Accuracy for training is: 0.7219084010153825 Accuracy for test is: 0.703759008238683\n",
      "\n",
      "*For model 235 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 4 -activation: relu -regularization cost: 0.1 \n",
      "Accuracy for training is: 0.7291283957498865 Accuracy for test is: 0.7156717069233616\n",
      "\n",
      "*For model 236 settings are: -epochs: 50 -hidden neurons: 50 -hidden layers: 4 -activation: relu -regularization cost: 0.05 \n",
      "Accuracy for training is: 0.730159287082113 Accuracy for test is: 0.7106622173466284\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-744a98a3714f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0;31m#statistics for train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m       \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_ls = [50, 100, 200] #50 y 100, 250\n",
    "nh_ls = [5,10,25,50,75,100] #minimo 5, maximo 25 de una en una (8-18)\n",
    "hl_ls = [1,2,3,4,5,6,7,8,9,10] #maximo 3 capas\n",
    "reg_ls = [1,0.75,0.5,0.1,0.05,0.01,0.005]\n",
    "activation_ls = ['relu'] #relu\n",
    "\n",
    "models = {}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for e in epochs_ls:\n",
    "        for nh in nh_ls:\n",
    "            for hl in hl_ls:\n",
    "                for r in reg_ls:\n",
    "                    for a in activation_ls:\n",
    "                    \n",
    "                        model = neuron_layers(10,nh,1,hl,a,r)\n",
    "\n",
    "                        model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "                        history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "                        #statistics for train\n",
    "                        y_hat= model.predict(X_train)\n",
    "                        acc_train = r2_score(Y_train, y_hat)\n",
    "                        mse_train = mean_squared_error(Y_train, y_hat)\n",
    "                        mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "                        rmse_train = mean_squared_error(Y_train, y_hat, squared=False)\n",
    "\n",
    "                        res_train = Y_train - y_hat\n",
    "                        std_res_train = round(res_train.std(),3)\n",
    "\n",
    "                        num_train = ((y_hat - Y_train)**2).sum()\n",
    "                        den_train = ((abs(y_hat - Y_train.mean()) + \n",
    "                                abs(Y_train - Y_train.mean()))**2).sum()\n",
    "                        ia_train = round(1 - (num_train / den_train),3)\n",
    "\n",
    "                        #accuracy for test\n",
    "                        y_hat = model.predict(X_test)\n",
    "                        acc_test = r2_score(Y_test, y_hat)\n",
    "                        mse_test = mean_squared_error(Y_test, y_hat)\n",
    "                        mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "                        rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "                        res_test = Y_test - y_hat\n",
    "                        std_res_test = round(res_test.std(),3)\n",
    "\n",
    "                        num_test = ((y_hat - Y_test)**2).sum()\n",
    "                        den_test = ((abs(y_hat - Y_test.mean()) + \n",
    "                                abs(Y_test - Y_test.mean()))**2).sum()\n",
    "                        ia_test = round(1 - (num_test / den_test),3)\n",
    "\n",
    "                        models['model'+str(i)] = [e, nh, hl, a, r, \n",
    "                                                               acc_train, mse_train, mae_train, rmse_train, std_res_train, ia_train,\n",
    "                                                               acc_test, mse_test, mae_test, rmse_test, std_res_test, ia_test]\n",
    "\n",
    "                        print ('\\n*For model',str(i),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "                               '-regularization cost:',r,\n",
    "                               '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test))\n",
    "                        \n",
    "                        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>model10</th>\n",
       "      <th>...</th>\n",
       "      <th>model1251</th>\n",
       "      <th>model1252</th>\n",
       "      <th>model1253</th>\n",
       "      <th>model1254</th>\n",
       "      <th>model1255</th>\n",
       "      <th>model1256</th>\n",
       "      <th>model1257</th>\n",
       "      <th>model1258</th>\n",
       "      <th>model1259</th>\n",
       "      <th>model1260</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.769816</td>\n",
       "      <td>-0.503817</td>\n",
       "      <td>0.752728</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>0.775487</td>\n",
       "      <td>0.768434</td>\n",
       "      <td>0.774627</td>\n",
       "      <td>0.77487</td>\n",
       "      <td>-0.503562</td>\n",
       "      <td>0.760738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.876707</td>\n",
       "      <td>0.842827</td>\n",
       "      <td>0.881065</td>\n",
       "      <td>0.853101</td>\n",
       "      <td>0.867192</td>\n",
       "      <td>0.870167</td>\n",
       "      <td>0.854923</td>\n",
       "      <td>0.879892</td>\n",
       "      <td>0.882754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>153.146995</td>\n",
       "      <td>1000.525475</td>\n",
       "      <td>164.515838</td>\n",
       "      <td>189.513019</td>\n",
       "      <td>149.374147</td>\n",
       "      <td>154.066418</td>\n",
       "      <td>149.946281</td>\n",
       "      <td>149.784519</td>\n",
       "      <td>1000.355852</td>\n",
       "      <td>159.186961</td>\n",
       "      <td>...</td>\n",
       "      <td>85.25089</td>\n",
       "      <td>82.029876</td>\n",
       "      <td>104.570892</td>\n",
       "      <td>79.130535</td>\n",
       "      <td>97.735554</td>\n",
       "      <td>88.360531</td>\n",
       "      <td>86.381222</td>\n",
       "      <td>96.523138</td>\n",
       "      <td>79.910403</td>\n",
       "      <td>78.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.308663</td>\n",
       "      <td>20.455751</td>\n",
       "      <td>8.458616</td>\n",
       "      <td>9.137971</td>\n",
       "      <td>8.138845</td>\n",
       "      <td>8.151289</td>\n",
       "      <td>7.951833</td>\n",
       "      <td>8.244184</td>\n",
       "      <td>20.453105</td>\n",
       "      <td>8.435771</td>\n",
       "      <td>...</td>\n",
       "      <td>6.120738</td>\n",
       "      <td>6.141205</td>\n",
       "      <td>6.960505</td>\n",
       "      <td>5.864301</td>\n",
       "      <td>6.46343</td>\n",
       "      <td>6.307355</td>\n",
       "      <td>6.198451</td>\n",
       "      <td>6.541824</td>\n",
       "      <td>6.035041</td>\n",
       "      <td>5.974908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.375257</td>\n",
       "      <td>31.631084</td>\n",
       "      <td>12.826373</td>\n",
       "      <td>13.766373</td>\n",
       "      <td>12.221872</td>\n",
       "      <td>12.412349</td>\n",
       "      <td>12.245255</td>\n",
       "      <td>12.238649</td>\n",
       "      <td>31.628403</td>\n",
       "      <td>12.616932</td>\n",
       "      <td>...</td>\n",
       "      <td>9.233141</td>\n",
       "      <td>9.057035</td>\n",
       "      <td>10.225991</td>\n",
       "      <td>8.895535</td>\n",
       "      <td>9.886129</td>\n",
       "      <td>9.400028</td>\n",
       "      <td>9.29415</td>\n",
       "      <td>9.824619</td>\n",
       "      <td>8.939262</td>\n",
       "      <td>8.83212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.317</td>\n",
       "      <td>25.794</td>\n",
       "      <td>12.806</td>\n",
       "      <td>13.761</td>\n",
       "      <td>12.222</td>\n",
       "      <td>12.412</td>\n",
       "      <td>12.183</td>\n",
       "      <td>12.176</td>\n",
       "      <td>25.794</td>\n",
       "      <td>12.617</td>\n",
       "      <td>...</td>\n",
       "      <td>9.226</td>\n",
       "      <td>8.885</td>\n",
       "      <td>10.029</td>\n",
       "      <td>8.895</td>\n",
       "      <td>9.599</td>\n",
       "      <td>9.364</td>\n",
       "      <td>9.285</td>\n",
       "      <td>9.824</td>\n",
       "      <td>8.935</td>\n",
       "      <td>8.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.756846</td>\n",
       "      <td>-0.525158</td>\n",
       "      <td>0.737603</td>\n",
       "      <td>0.705557</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.753428</td>\n",
       "      <td>0.761644</td>\n",
       "      <td>0.765378</td>\n",
       "      <td>-0.524892</td>\n",
       "      <td>0.748985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755154</td>\n",
       "      <td>0.750052</td>\n",
       "      <td>0.736947</td>\n",
       "      <td>0.758136</td>\n",
       "      <td>0.757886</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.76607</td>\n",
       "      <td>0.759645</td>\n",
       "      <td>0.762081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>155.684865</td>\n",
       "      <td>976.515039</td>\n",
       "      <td>168.005137</td>\n",
       "      <td>188.523282</td>\n",
       "      <td>154.945734</td>\n",
       "      <td>157.872719</td>\n",
       "      <td>152.612738</td>\n",
       "      <td>150.22185</td>\n",
       "      <td>976.345152</td>\n",
       "      <td>160.717954</td>\n",
       "      <td>...</td>\n",
       "      <td>156.767765</td>\n",
       "      <td>160.034484</td>\n",
       "      <td>168.425238</td>\n",
       "      <td>154.858317</td>\n",
       "      <td>155.018697</td>\n",
       "      <td>149.987482</td>\n",
       "      <td>156.752558</td>\n",
       "      <td>149.778795</td>\n",
       "      <td>153.892687</td>\n",
       "      <td>152.33294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.299926</td>\n",
       "      <td>20.416087</td>\n",
       "      <td>8.512054</td>\n",
       "      <td>9.123379</td>\n",
       "      <td>8.184086</td>\n",
       "      <td>8.210807</td>\n",
       "      <td>7.991076</td>\n",
       "      <td>8.191844</td>\n",
       "      <td>20.41332</td>\n",
       "      <td>8.461383</td>\n",
       "      <td>...</td>\n",
       "      <td>8.031331</td>\n",
       "      <td>8.15594</td>\n",
       "      <td>8.435769</td>\n",
       "      <td>7.932549</td>\n",
       "      <td>8.001137</td>\n",
       "      <td>8.135505</td>\n",
       "      <td>7.933114</td>\n",
       "      <td>7.994451</td>\n",
       "      <td>8.006298</td>\n",
       "      <td>7.986223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.477374</td>\n",
       "      <td>31.249241</td>\n",
       "      <td>12.96168</td>\n",
       "      <td>13.730378</td>\n",
       "      <td>12.44772</td>\n",
       "      <td>12.564741</td>\n",
       "      <td>12.353653</td>\n",
       "      <td>12.256502</td>\n",
       "      <td>31.246522</td>\n",
       "      <td>12.677458</td>\n",
       "      <td>...</td>\n",
       "      <td>12.520693</td>\n",
       "      <td>12.650474</td>\n",
       "      <td>12.977875</td>\n",
       "      <td>12.444208</td>\n",
       "      <td>12.45065</td>\n",
       "      <td>12.246938</td>\n",
       "      <td>12.520086</td>\n",
       "      <td>12.238415</td>\n",
       "      <td>12.405349</td>\n",
       "      <td>12.342323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.437</td>\n",
       "      <td>25.304</td>\n",
       "      <td>12.927</td>\n",
       "      <td>13.722</td>\n",
       "      <td>12.444</td>\n",
       "      <td>12.56</td>\n",
       "      <td>12.267</td>\n",
       "      <td>12.218</td>\n",
       "      <td>25.304</td>\n",
       "      <td>12.676</td>\n",
       "      <td>...</td>\n",
       "      <td>12.509</td>\n",
       "      <td>12.572</td>\n",
       "      <td>12.86</td>\n",
       "      <td>12.436</td>\n",
       "      <td>12.145</td>\n",
       "      <td>12.242</td>\n",
       "      <td>12.496</td>\n",
       "      <td>12.236</td>\n",
       "      <td>12.405</td>\n",
       "      <td>12.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows  1260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model1       model2      model3      model4      model5      model6  \\\n",
       "0           50           50          50          50          50          50   \n",
       "1            5            5           5           5           5           5   \n",
       "2            1            1           1           1           1           1   \n",
       "3         relu         relu        relu        relu        relu        relu   \n",
       "4            1         0.75         0.5         0.1        0.05        0.01   \n",
       "5     0.769816    -0.503817    0.752728    0.715157    0.775487    0.768434   \n",
       "6   153.146995  1000.525475  164.515838  189.513019  149.374147  154.066418   \n",
       "7     8.308663    20.455751    8.458616    9.137971    8.138845    8.151289   \n",
       "8    12.375257    31.631084   12.826373   13.766373   12.221872   12.412349   \n",
       "9       12.317       25.794      12.806      13.761      12.222      12.412   \n",
       "10       0.933        0.398       0.923       0.911       0.933       0.931   \n",
       "11    0.756846    -0.525158    0.737603    0.705557       0.758    0.753428   \n",
       "12  155.684865   976.515039  168.005137  188.523282  154.945734  157.872719   \n",
       "13    8.299926    20.416087    8.512054    9.123379    8.184086    8.210807   \n",
       "14   12.477374    31.249241    12.96168   13.730378    12.44772   12.564741   \n",
       "15      12.437       25.304      12.927      13.722      12.444       12.56   \n",
       "16       0.929        0.401       0.919       0.909       0.929       0.926   \n",
       "\n",
       "        model7      model8       model9     model10  ...   model1251  \\\n",
       "0           50          50           50          50  ...         200   \n",
       "1            5           5            5           5  ...         100   \n",
       "2            1           2            2           2  ...           9   \n",
       "3         relu        relu         relu        relu  ...        relu   \n",
       "4        0.005           1         0.75         0.5  ...        0.05   \n",
       "5     0.774627     0.77487    -0.503562    0.760738  ...    0.871866   \n",
       "6   149.946281  149.784519  1000.355852  159.186961  ...    85.25089   \n",
       "7     7.951833    8.244184    20.453105    8.435771  ...    6.120738   \n",
       "8    12.245255   12.238649    31.628403   12.616932  ...    9.233141   \n",
       "9       12.183      12.176       25.794      12.617  ...       9.226   \n",
       "10       0.931       0.935        0.398       0.928  ...       0.965   \n",
       "11    0.761644    0.765378    -0.524892    0.748985  ...    0.755154   \n",
       "12  152.612738   150.22185   976.345152  160.717954  ...  156.767765   \n",
       "13    7.991076    8.191844     20.41332    8.461383  ...    8.031331   \n",
       "14   12.353653   12.256502    31.246522   12.677458  ...   12.520693   \n",
       "15      12.267      12.218       25.304      12.676  ...      12.509   \n",
       "16       0.928       0.933        0.401       0.925  ...       0.931   \n",
       "\n",
       "     model1252   model1253   model1254   model1255   model1256   model1257  \\\n",
       "0          200         200         200         200         200         200   \n",
       "1          100         100         100         100         100         100   \n",
       "2            9           9          10          10          10          10   \n",
       "3         relu        relu        relu        relu        relu        relu   \n",
       "4         0.01       0.005           1        0.75         0.5         0.1   \n",
       "5     0.876707    0.842827    0.881065    0.853101    0.867192    0.870167   \n",
       "6    82.029876  104.570892   79.130535   97.735554   88.360531   86.381222   \n",
       "7     6.141205    6.960505    5.864301     6.46343    6.307355    6.198451   \n",
       "8     9.057035   10.225991    8.895535    9.886129    9.400028     9.29415   \n",
       "9        8.885      10.029       8.895       9.599       9.364       9.285   \n",
       "10       0.969       0.959       0.969       0.956       0.965       0.963   \n",
       "11    0.750052    0.736947    0.758136    0.757886    0.765744    0.755178   \n",
       "12  160.034484  168.425238  154.858317  155.018697  149.987482  156.752558   \n",
       "13     8.15594    8.435769    7.932549    8.001137    8.135505    7.933114   \n",
       "14   12.650474   12.977875   12.444208    12.45065   12.246938   12.520086   \n",
       "15      12.572       12.86      12.436      12.145      12.242      12.496   \n",
       "16       0.935       0.931       0.933       0.924       0.935       0.927   \n",
       "\n",
       "     model1258   model1259  model1260  \n",
       "0          200         200        200  \n",
       "1          100         100        100  \n",
       "2           10          10         10  \n",
       "3         relu        relu       relu  \n",
       "4         0.05        0.01      0.005  \n",
       "5     0.854923    0.879892   0.882754  \n",
       "6    96.523138   79.910403  78.006346  \n",
       "7     6.541824    6.035041   5.974908  \n",
       "8     9.824619    8.939262    8.83212  \n",
       "9        9.824       8.935      8.832  \n",
       "10        0.96       0.969      0.968  \n",
       "11     0.76607    0.759645   0.762081  \n",
       "12  149.778795  153.892687  152.33294  \n",
       "13    7.994451    8.006298   7.986223  \n",
       "14   12.238415   12.405349  12.342323  \n",
       "15      12.236      12.405     12.337  \n",
       "16       0.935       0.935      0.932  \n",
       "\n",
       "[17 rows x 1260 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.DataFrame(models)\n",
    "df_models.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.to_csv('../output/data/nn_RawModels_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>regularization</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>std_res_train</th>\n",
       "      <th>ia_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>std_res_test</th>\n",
       "      <th>ia_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769816</td>\n",
       "      <td>153.146995</td>\n",
       "      <td>8.308663</td>\n",
       "      <td>12.375257</td>\n",
       "      <td>12.317</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.756846</td>\n",
       "      <td>155.684865</td>\n",
       "      <td>8.299926</td>\n",
       "      <td>12.477374</td>\n",
       "      <td>12.437</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.503817</td>\n",
       "      <td>1000.525475</td>\n",
       "      <td>20.455751</td>\n",
       "      <td>31.631084</td>\n",
       "      <td>25.794</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.525158</td>\n",
       "      <td>976.515039</td>\n",
       "      <td>20.416087</td>\n",
       "      <td>31.249241</td>\n",
       "      <td>25.304</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752728</td>\n",
       "      <td>164.515838</td>\n",
       "      <td>8.458616</td>\n",
       "      <td>12.826373</td>\n",
       "      <td>12.806</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.737603</td>\n",
       "      <td>168.005137</td>\n",
       "      <td>8.512054</td>\n",
       "      <td>12.96168</td>\n",
       "      <td>12.927</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.715157</td>\n",
       "      <td>189.513019</td>\n",
       "      <td>9.137971</td>\n",
       "      <td>13.766373</td>\n",
       "      <td>13.761</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.705557</td>\n",
       "      <td>188.523282</td>\n",
       "      <td>9.123379</td>\n",
       "      <td>13.730378</td>\n",
       "      <td>13.722</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.775487</td>\n",
       "      <td>149.374147</td>\n",
       "      <td>8.138845</td>\n",
       "      <td>12.221872</td>\n",
       "      <td>12.222</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.758</td>\n",
       "      <td>154.945734</td>\n",
       "      <td>8.184086</td>\n",
       "      <td>12.44772</td>\n",
       "      <td>12.444</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       epochs hidden_neurons hidden_layers activation regularization  \\\n",
       "model1     50              5             1       relu              1   \n",
       "model2     50              5             1       relu           0.75   \n",
       "model3     50              5             1       relu            0.5   \n",
       "model4     50              5             1       relu            0.1   \n",
       "model5     50              5             1       relu           0.05   \n",
       "\n",
       "       acc_train    mse_train  mae_train rmse_train std_res_train ia_train  \\\n",
       "model1  0.769816   153.146995   8.308663  12.375257        12.317    0.933   \n",
       "model2 -0.503817  1000.525475  20.455751  31.631084        25.794    0.398   \n",
       "model3  0.752728   164.515838   8.458616  12.826373        12.806    0.923   \n",
       "model4  0.715157   189.513019   9.137971  13.766373        13.761    0.911   \n",
       "model5  0.775487   149.374147   8.138845  12.221872        12.222    0.933   \n",
       "\n",
       "        acc_test    mse_test   mae_test  rmse_test std_res_test ia_test  \n",
       "model1  0.756846  155.684865   8.299926  12.477374       12.437   0.929  \n",
       "model2 -0.525158  976.515039  20.416087  31.249241       25.304   0.401  \n",
       "model3  0.737603  168.005137   8.512054   12.96168       12.927   0.919  \n",
       "model4  0.705557  188.523282   9.123379  13.730378       13.722   0.909  \n",
       "model5     0.758  154.945734   8.184086   12.44772       12.444   0.929  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = df_models.transpose()\n",
    "df_models = df_models.rename(columns={0:'epochs',1:'hidden_neurons',2:'hidden_layers',3:'activation',\n",
    "                        4:'regularization',5:'acc_train',6:'mse_train',7:'mae_train',\n",
    "                        8:'rmse_train',9:'std_res_train',10:'ia_train',11:'acc_test',\n",
    "                         12:'mse_test',13:'mae_test',14:'rmse_test',15:'std_res_test',16:'ia_test'})\n",
    "print(df_models.shape)\n",
    "df_models.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['acc_train','mse_train','mae_train','rmse_train',\n",
    "       'std_res_train','ia_train','acc_test','mse_test','mae_test',\n",
    "       'rmse_test','std_res_test','ia_test']\n",
    "for c in cols:\n",
    "    df_models[c] = pd.to_numeric(df_models[c])\n",
    "    df_models[c] = round(df_models[c],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.to_csv('../output/data/nn_models_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models = pd.DataFrame(columns=['model','variable','result'])\n",
    "\n",
    "min_cols = ['mse_train','mae_train','rmse_train',\n",
    "       'mse_test','mae_test','rmse_test']\n",
    "max_cols = ['acc_train','ia_train',\n",
    "            'acc_test','ia_test']\n",
    "\n",
    "i = 0\n",
    "for c in min_cols:\n",
    "    val = df_models[c].min()\n",
    "    df_tmp = df_models.loc[df_models[c]==val].copy()\n",
    "    df_tmp[['epochs']] = df_tmp[['epochs']]/200\n",
    "    df_tmp[['hidden_neurons']] = df_tmp[['hidden_neurons']]/100\n",
    "    df_tmp[['hidden_layers']] = df_tmp[['hidden_layers']]/10\n",
    "    df_tmp[['regularization']] = df_tmp[['regularization']]/1\n",
    "    model = df_tmp[['epochs','hidden_neurons',\n",
    "                    'hidden_layers','regularization']].sum(axis=1).idxmin()\n",
    "    df_best_models.loc[i] = [model, c, val]\n",
    "    i += 1\n",
    "    \n",
    "for c in max_cols:\n",
    "    val = df_models[c].max()\n",
    "    df_tmp = df_models.loc[df_models[c]==val].copy()\n",
    "    df_tmp[['epochs']] = df_tmp[['epochs']]/200\n",
    "    df_tmp[['hidden_neurons']] = df_tmp[['hidden_neurons']]/100\n",
    "    df_tmp[['hidden_layers']] = df_tmp[['hidden_layers']]/10\n",
    "    df_tmp[['regularization']] = df_tmp[['regularization']]/1\n",
    "    model = df_tmp[['epochs','hidden_neurons',\n",
    "                    'hidden_layers','regularization']].sum(axis=1).idxmin()\n",
    "    df_best_models.loc[i] = [model, c, val]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>variable</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1209</td>\n",
       "      <td>mse_train</td>\n",
       "      <td>76.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model1254</td>\n",
       "      <td>mae_train</td>\n",
       "      <td>5.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model1209</td>\n",
       "      <td>rmse_train</td>\n",
       "      <td>8.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model732</td>\n",
       "      <td>mse_test</td>\n",
       "      <td>130.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model737</td>\n",
       "      <td>mae_test</td>\n",
       "      <td>7.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model732</td>\n",
       "      <td>rmse_test</td>\n",
       "      <td>11.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model1209</td>\n",
       "      <td>acc_train</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model1230</td>\n",
       "      <td>ia_train</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model732</td>\n",
       "      <td>acc_test</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model788</td>\n",
       "      <td>ia_test</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model    variable   result\n",
       "0  model1209   mse_train   76.078\n",
       "1  model1254   mae_train    5.864\n",
       "2  model1209  rmse_train    8.722\n",
       "3   model732    mse_test  130.450\n",
       "4   model737    mae_test    7.472\n",
       "5   model732   rmse_test   11.421\n",
       "6  model1209   acc_train    0.886\n",
       "7  model1230    ia_train    0.970\n",
       "8   model732    acc_test    0.796\n",
       "9   model788     ia_test    0.944"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models.to_csv('../output/data/RNA/BestModels_Notebook6b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = ['epochs','hidden_neurons',\n",
    "            'hidden_layers','regularization']\n",
    "\n",
    "for m in model_var:\n",
    "    df_models.groupby([m]).agg(['mean','std']).to_csv(f'../output/data/RNA/{m}_ModelAnalysis_Notebook6b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">hidden_neurons</th>\n",
       "      <th colspan=\"2\" halign=\"left\">hidden_layers</th>\n",
       "      <th colspan=\"2\" halign=\"left\">regularization</th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc_train</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse_train</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mse_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mae_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rmse_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_res_test</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ia_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>44.166667</td>\n",
       "      <td>34.61201</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.875707</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.376889</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>0.178830</td>\n",
       "      <td>153.063760</td>\n",
       "      <td>118.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>163.744714</td>\n",
       "      <td>113.805352</td>\n",
       "      <td>8.211683</td>\n",
       "      <td>1.735393</td>\n",
       "      <td>12.521298</td>\n",
       "      <td>2.641624</td>\n",
       "      <td>12.304010</td>\n",
       "      <td>1.843284</td>\n",
       "      <td>0.923243</td>\n",
       "      <td>0.073054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>44.166667</td>\n",
       "      <td>34.61201</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.875707</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.376889</td>\n",
       "      <td>0.796783</td>\n",
       "      <td>0.108476</td>\n",
       "      <td>135.209443</td>\n",
       "      <td>72.177703</td>\n",
       "      <td>...</td>\n",
       "      <td>153.929086</td>\n",
       "      <td>65.213602</td>\n",
       "      <td>8.028779</td>\n",
       "      <td>1.246567</td>\n",
       "      <td>12.281976</td>\n",
       "      <td>1.757637</td>\n",
       "      <td>12.207279</td>\n",
       "      <td>1.733325</td>\n",
       "      <td>0.920905</td>\n",
       "      <td>0.105124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>44.166667</td>\n",
       "      <td>34.61201</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.875707</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.376889</td>\n",
       "      <td>0.815948</td>\n",
       "      <td>0.103057</td>\n",
       "      <td>122.451767</td>\n",
       "      <td>68.563434</td>\n",
       "      <td>...</td>\n",
       "      <td>155.139198</td>\n",
       "      <td>58.903670</td>\n",
       "      <td>8.050943</td>\n",
       "      <td>1.186469</td>\n",
       "      <td>12.354119</td>\n",
       "      <td>1.587603</td>\n",
       "      <td>12.304467</td>\n",
       "      <td>1.590300</td>\n",
       "      <td>0.920536</td>\n",
       "      <td>0.110536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hidden_neurons           hidden_layers           regularization  \\\n",
       "                 mean       std          mean       std           mean   \n",
       "epochs                                                                   \n",
       "50          44.166667  34.61201           5.5  2.875707          0.345   \n",
       "100         44.166667  34.61201           5.5  2.875707          0.345   \n",
       "200         44.166667  34.61201           5.5  2.875707          0.345   \n",
       "\n",
       "                 acc_train             mse_train              ...    mse_test  \\\n",
       "             std      mean       std        mean         std  ...        mean   \n",
       "epochs                                                        ...               \n",
       "50      0.376889  0.769952  0.178830  153.063760  118.965629  ...  163.744714   \n",
       "100     0.376889  0.796783  0.108476  135.209443   72.177703  ...  153.929086   \n",
       "200     0.376889  0.815948  0.103057  122.451767   68.563434  ...  155.139198   \n",
       "\n",
       "                    mae_test            rmse_test           std_res_test  \\\n",
       "               std      mean       std       mean       std         mean   \n",
       "epochs                                                                     \n",
       "50      113.805352  8.211683  1.735393  12.521298  2.641624    12.304010   \n",
       "100      65.213602  8.028779  1.246567  12.281976  1.757637    12.207279   \n",
       "200      58.903670  8.050943  1.186469  12.354119  1.587603    12.304467   \n",
       "\n",
       "                   ia_test            \n",
       "             std      mean       std  \n",
       "epochs                                \n",
       "50      1.843284  0.923243  0.073054  \n",
       "100     1.733325  0.920905  0.105124  \n",
       "200     1.590300  0.920536  0.110536  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models.groupby(['epochs']).agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
