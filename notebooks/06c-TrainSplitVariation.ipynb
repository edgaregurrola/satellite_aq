{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import regularizers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27504, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>PARAM</th>\n",
       "      <th>AGU</th>\n",
       "      <th>ATM</th>\n",
       "      <th>CEN</th>\n",
       "      <th>LDO</th>\n",
       "      <th>LPIN</th>\n",
       "      <th>MIR</th>\n",
       "      <th>OBL</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>00:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>49.92</td>\n",
       "      <td>146.95</td>\n",
       "      <td>86.12</td>\n",
       "      <td>174.04</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>197.67</td>\n",
       "      <td>115.54</td>\n",
       "      <td>143.40</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>01:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>115.27</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.99</td>\n",
       "      <td>138.09</td>\n",
       "      <td>84.24</td>\n",
       "      <td>100.46</td>\n",
       "      <td>29.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>02:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>52.71</td>\n",
       "      <td>113.44</td>\n",
       "      <td>63.93</td>\n",
       "      <td>99.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.70</td>\n",
       "      <td>98.79</td>\n",
       "      <td>135.39</td>\n",
       "      <td>82.05</td>\n",
       "      <td>30.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>03:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>51.24</td>\n",
       "      <td>73.30</td>\n",
       "      <td>60.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.30</td>\n",
       "      <td>97.94</td>\n",
       "      <td>117.60</td>\n",
       "      <td>114.74</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>04:00</td>\n",
       "      <td>PM10</td>\n",
       "      <td>58.84</td>\n",
       "      <td>52.55</td>\n",
       "      <td>108.09</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.89</td>\n",
       "      <td>134.39</td>\n",
       "      <td>164.68</td>\n",
       "      <td>118.83</td>\n",
       "      <td>51.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FECHA   HORA PARAM    AGU     ATM     CEN     LDO  LPIN  \\\n",
       "4   2016-01-01 00:00:00  00:00  PM10  49.92  146.95   86.12  174.04  -1.0   \n",
       "13  2016-01-01 01:00:00  01:00  PM10  52.80   -1.00   46.49  115.27  -1.0   \n",
       "22  2016-01-01 02:00:00  02:00  PM10  52.71  113.44   63.93   99.00  -1.0   \n",
       "31  2016-01-01 03:00:00  03:00  PM10  51.24   73.30   60.75   83.65  -1.0   \n",
       "40  2016-01-01 04:00:00  04:00  PM10  58.84   52.55  108.09   49.70  -1.0   \n",
       "\n",
       "       MIR     OBL     SFE     TLA    VAL  \n",
       "4    69.75  197.67  115.54  143.40  17.08  \n",
       "13   68.99  138.09   84.24  100.46  29.15  \n",
       "22  117.70   98.79  135.39   82.05  30.89  \n",
       "31  160.30   97.94  117.60  114.74  38.74  \n",
       "40  180.89  134.39  164.68  118.83  51.48  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_gdl = '../data/processed/2016-2019_3std_preprocessed.csv'\n",
    "df = pd.read_csv(dir_gdl)\n",
    "df_data = df[df['PARAM']=='PM10'].fillna(-1)\n",
    "df_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_data = df_data[df_data.CEN != -1] #Elimina valores negativos en la columna de salida\n",
    "print(df_data.shape)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "xscale = X_std * (1 - 0) + 0\n",
    "xscale[X==-1]=-1\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(Y)\n",
    "yscale=scaler_y.transform(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layers(nx,nh,ny,hl,act,r, seed=None):\n",
    "    \n",
    "    tf.keras.regularizers.l1(l1=r)\n",
    "    \n",
    "    initializer = tf.keras.initializers.RandomNormal(seed=seed)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(1, 3+hl):\n",
    "        \n",
    "        if i == 1:\n",
    "            model.add(Dense(nx, input_dim=9, kernel_initializer=initializer,\n",
    "                            activation=act,kernel_regularizer='l1'))\n",
    "            \n",
    "        elif i == (2+hl):\n",
    "            model.add(Dense(ny, activation='linear'))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(nh, activation=act))\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>regularization</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>std_res_train</th>\n",
       "      <th>ia_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>std_res_test</th>\n",
       "      <th>ia_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.770</td>\n",
       "      <td>153.147</td>\n",
       "      <td>8.309</td>\n",
       "      <td>12.375</td>\n",
       "      <td>12.317</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.757</td>\n",
       "      <td>155.685</td>\n",
       "      <td>8.300</td>\n",
       "      <td>12.477</td>\n",
       "      <td>12.437</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>1000.525</td>\n",
       "      <td>20.456</td>\n",
       "      <td>31.631</td>\n",
       "      <td>25.794</td>\n",
       "      <td>0.398</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>976.515</td>\n",
       "      <td>20.416</td>\n",
       "      <td>31.249</td>\n",
       "      <td>25.304</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model3</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.753</td>\n",
       "      <td>164.516</td>\n",
       "      <td>8.459</td>\n",
       "      <td>12.826</td>\n",
       "      <td>12.806</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.738</td>\n",
       "      <td>168.005</td>\n",
       "      <td>8.512</td>\n",
       "      <td>12.962</td>\n",
       "      <td>12.927</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model4</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.715</td>\n",
       "      <td>189.513</td>\n",
       "      <td>9.138</td>\n",
       "      <td>13.766</td>\n",
       "      <td>13.761</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.706</td>\n",
       "      <td>188.523</td>\n",
       "      <td>9.123</td>\n",
       "      <td>13.730</td>\n",
       "      <td>13.722</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model5</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.775</td>\n",
       "      <td>149.374</td>\n",
       "      <td>8.139</td>\n",
       "      <td>12.222</td>\n",
       "      <td>12.222</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.758</td>\n",
       "      <td>154.946</td>\n",
       "      <td>8.184</td>\n",
       "      <td>12.448</td>\n",
       "      <td>12.444</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number  epochs  hidden_neurons  hidden_layers activation  \\\n",
       "0       model1      50               5              1       relu   \n",
       "1       model2      50               5              1       relu   \n",
       "2       model3      50               5              1       relu   \n",
       "3       model4      50               5              1       relu   \n",
       "4       model5      50               5              1       relu   \n",
       "\n",
       "   regularization  acc_train  mse_train  mae_train  rmse_train  std_res_train  \\\n",
       "0            1.00      0.770    153.147      8.309      12.375         12.317   \n",
       "1            0.75     -0.504   1000.525     20.456      31.631         25.794   \n",
       "2            0.50      0.753    164.516      8.459      12.826         12.806   \n",
       "3            0.10      0.715    189.513      9.138      13.766         13.761   \n",
       "4            0.05      0.775    149.374      8.139      12.222         12.222   \n",
       "\n",
       "   ia_train  acc_test  mse_test  mae_test  rmse_test  std_res_test  ia_test  \n",
       "0     0.933     0.757   155.685     8.300     12.477        12.437    0.929  \n",
       "1     0.398    -0.525   976.515    20.416     31.249        25.304    0.401  \n",
       "2     0.923     0.738   168.005     8.512     12.962        12.927    0.919  \n",
       "3     0.911     0.706   188.523     9.123     13.730        13.722    0.909  \n",
       "4     0.933     0.758   154.946     8.184     12.448        12.444    0.929  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = pd.read_csv('../output/data/RNA/NN_ModelsNotebook6b_v1.csv')\n",
    "nn.rename(columns={'Unnamed: 0':'model_number'}, inplace=True)\n",
    "print(nn.shape)\n",
    "nn.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>variable</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model1209</td>\n",
       "      <td>mse_train</td>\n",
       "      <td>76.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>model1254</td>\n",
       "      <td>mae_train</td>\n",
       "      <td>5.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>model1209</td>\n",
       "      <td>rmse_train</td>\n",
       "      <td>8.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>model732</td>\n",
       "      <td>mse_test</td>\n",
       "      <td>130.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      model    variable   result\n",
       "0           0  model1209   mse_train   76.078\n",
       "1           1  model1254   mae_train    5.864\n",
       "2           2  model1209  rmse_train    8.722\n",
       "3           3   model732    mse_test  130.450"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bestmodels = pd.read_csv('../output/data/RNA/BestModels_Notebook6b.csv')\n",
    "print(df_bestmodels.shape)\n",
    "df_bestmodels.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Iteration over one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "i = 789\n",
    "nh = int(nn.iloc[:,i+1]['hidden_neurons'])\n",
    "hl = int(nn.iloc[:,i+1]['hidden_layers'])\n",
    "e = int(nn.iloc[:,i+1]['epochs'])\n",
    "a = nn.iloc[:,i+1]['activation']\n",
    "\n",
    "models = {}\n",
    "r = 0.01\n",
    "\n",
    "for c in range(100):\n",
    "    \n",
    "    X,Y = df_data[['AGU','ATM','LDO','LPIN','MIR','OBL','SFE','TLA','VAL']].to_numpy(), df_data[\"CEN\"].to_numpy()   #separate data into input and output features\n",
    "\n",
    "    Y=np.reshape(Y, (-1,1))\n",
    "\n",
    "    X_std = (X - np.nanmin(np.where(X>=0, X, np.nan),axis=0)) / (X.max(axis=0) - np.nanmin(np.where(X>=0, X, np.nan),axis=0))\n",
    "    xscale = X_std * (1 - 0) + 0\n",
    "    xscale[X==-1]=-1\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit(Y)\n",
    "    yscale=scaler_y.transform(Y)\n",
    "\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2) #split\n",
    "        \n",
    "    model = neuron_layers(10,nh,1,hl,a,r, 1)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=e, batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "    #statistics for train\n",
    "    y_hat= model.predict(X_train)\n",
    "    acc_train = r2_score(Y_train, y_hat)\n",
    "    mse_train = mean_squared_error(Y_train, y_hat)\n",
    "    mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "    rmse_train = mean_squared_error(Y_train, y_hat, squared=False)\n",
    "\n",
    "    res_train = Y_train - y_hat\n",
    "    std_res_train = round(res_train.std(),3)\n",
    "\n",
    "    num_train = ((y_hat - Y_train)**2).sum()\n",
    "    den_train = ((abs(y_hat - Y_train.mean()) + \n",
    "            abs(Y_train - Y_train.mean()))**2).sum()\n",
    "    ia_train = round(1 - (num_train / den_train),3)\n",
    "\n",
    "    #accuracy for test\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc_test = r2_score(Y_test, y_hat)\n",
    "    mse_test = mean_squared_error(Y_test, y_hat)\n",
    "    mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "    rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "    res_test = Y_test - y_hat\n",
    "    std_res_test = round(res_test.std(),3)\n",
    "\n",
    "    num_test = ((y_hat - Y_test)**2).sum()\n",
    "    den_test = ((abs(y_hat - Y_test.mean()) + \n",
    "            abs(Y_test - Y_test.mean()))**2).sum()\n",
    "    ia_test = round(1 - (num_test / den_test),3)\n",
    "\n",
    "    models['model'+str(i+1)+'-'+str(r)] = [e, nh, hl, a, r, \n",
    "                                           acc_train, mse_train, mae_train, rmse_train, std_res_train, ia_train\n",
    "                                           acc_test, mse_test, mae_test, rmse_test, std_res_test, ia_test]\n",
    "\n",
    "    print ('\\n*For model',str(i+1),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "           '-regularization cost:',r,\n",
    "           '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test),\n",
    "          '\\nMSE for training is:', str(mse_train),'MSE for test is:',str(mse_test),\n",
    "           '\\nMAE for training is:', str(mae_train),'MAE for test is:',str(mae_test),\n",
    "           '\\nRMSE for training is:', str(rmse_train),'RMSE for test is:',str(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for different seeds in train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*For model 1 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 0 \n",
      "Accuracy for training is: 0.8720357126067578 Accuracy for test is: 0.7702782799800847\n",
      "\n",
      "*For model 2 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 2 \n",
      "Accuracy for training is: 0.8608201262861888 Accuracy for test is: 0.7787189891666119\n",
      "\n",
      "*For model 3 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 4 \n",
      "Accuracy for training is: 0.8768334878105168 Accuracy for test is: 0.7514542059731786\n",
      "\n",
      "*For model 4 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 6 \n",
      "Accuracy for training is: 0.8677000456059568 Accuracy for test is: 0.7780860552422286\n",
      "\n",
      "*For model 5 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 8 \n",
      "Accuracy for training is: 0.8700761631812185 Accuracy for test is: 0.7753258891754121\n",
      "\n",
      "*For model 6 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 10 \n",
      "Accuracy for training is: 0.8485599159098267 Accuracy for test is: 0.7715321487169466\n",
      "\n",
      "*For model 7 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 12 \n",
      "Accuracy for training is: 0.8662200982014596 Accuracy for test is: 0.7763181398943312\n",
      "\n",
      "*For model 8 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 14 \n",
      "Accuracy for training is: 0.8714006304397207 Accuracy for test is: 0.7491879002773989\n",
      "\n",
      "*For model 9 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 16 \n",
      "Accuracy for training is: 0.8681227670580742 Accuracy for test is: 0.7552449870775373\n",
      "\n",
      "*For model 10 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 18 \n",
      "Accuracy for training is: 0.8564818903397503 Accuracy for test is: 0.7767842031280892\n",
      "\n",
      "*For model 11 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 20 \n",
      "Accuracy for training is: 0.8744487307957058 Accuracy for test is: 0.7781095739121551\n",
      "\n",
      "*For model 12 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 22 \n",
      "Accuracy for training is: 0.8724948371771644 Accuracy for test is: 0.7688290115588732\n",
      "\n",
      "*For model 13 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 24 \n",
      "Accuracy for training is: 0.8452694584072861 Accuracy for test is: 0.7650911282184608\n",
      "\n",
      "*For model 14 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 26 \n",
      "Accuracy for training is: 0.8506671668742714 Accuracy for test is: 0.7806252396294004\n",
      "\n",
      "*For model 15 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 28 \n",
      "Accuracy for training is: 0.8772669807133675 Accuracy for test is: 0.7592935920144936\n",
      "\n",
      "*For model 16 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 30 \n",
      "Accuracy for training is: 0.8552168360439004 Accuracy for test is: 0.7596764525240443\n",
      "\n",
      "*For model 17 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 32 \n",
      "Accuracy for training is: 0.8397730677324249 Accuracy for test is: 0.7821537658628411\n",
      "\n",
      "*For model 18 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 34 \n",
      "Accuracy for training is: 0.8612074051809764 Accuracy for test is: 0.7549761946772677\n",
      "\n",
      "*For model 19 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 36 \n",
      "Accuracy for training is: 0.8817537240999458 Accuracy for test is: 0.7445387816068936\n",
      "\n",
      "*For model 20 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 38 \n",
      "Accuracy for training is: 0.8749653341912689 Accuracy for test is: 0.7512813088325486\n",
      "\n",
      "*For model 21 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 40 \n",
      "Accuracy for training is: 0.860214796587958 Accuracy for test is: 0.7688915730213631\n",
      "\n",
      "*For model 22 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 42 \n",
      "Accuracy for training is: 0.8654926588083037 Accuracy for test is: 0.7610755792673607\n",
      "\n",
      "*For model 23 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 44 \n",
      "Accuracy for training is: 0.8649895050330116 Accuracy for test is: 0.7553736238491995\n",
      "\n",
      "*For model 24 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 46 \n",
      "Accuracy for training is: 0.8676141066359349 Accuracy for test is: 0.7374132418086433\n",
      "\n",
      "*For model 25 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 48 \n",
      "Accuracy for training is: 0.8732021197568026 Accuracy for test is: 0.7489464079803775\n",
      "\n",
      "*For model 26 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 50 \n",
      "Accuracy for training is: 0.8721054583683521 Accuracy for test is: 0.7689908626956309\n",
      "\n",
      "*For model 27 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 52 \n",
      "Accuracy for training is: 0.8636503223257559 Accuracy for test is: 0.7752714179632945\n",
      "\n",
      "*For model 28 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 54 \n",
      "Accuracy for training is: 0.8636384387960592 Accuracy for test is: 0.7776081575602175\n",
      "\n",
      "*For model 29 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 56 \n",
      "Accuracy for training is: 0.857127284323089 Accuracy for test is: 0.7690331429296663\n",
      "\n",
      "*For model 30 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 58 \n",
      "Accuracy for training is: 0.8505533037999362 Accuracy for test is: 0.7835532835697177\n",
      "\n",
      "*For model 31 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 60 \n",
      "Accuracy for training is: 0.8483669236575343 Accuracy for test is: 0.774242868025276\n",
      "\n",
      "*For model 32 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 62 \n",
      "Accuracy for training is: 0.8655408005623185 Accuracy for test is: 0.7360622606103653\n",
      "\n",
      "*For model 33 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 64 \n",
      "Accuracy for training is: 0.8575097118623283 Accuracy for test is: 0.7533215580618806\n",
      "\n",
      "*For model 34 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 66 \n",
      "Accuracy for training is: 0.8564395805985384 Accuracy for test is: 0.7675144285547522\n",
      "\n",
      "*For model 35 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 68 \n",
      "Accuracy for training is: 0.8708624860120179 Accuracy for test is: 0.763248429296862\n",
      "\n",
      "*For model 36 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 70 \n",
      "Accuracy for training is: 0.8564853174643425 Accuracy for test is: 0.7582171761593343\n",
      "\n",
      "*For model 37 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 72 \n",
      "Accuracy for training is: 0.8656702736845657 Accuracy for test is: 0.7665985843737925\n",
      "\n",
      "*For model 38 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 74 \n",
      "Accuracy for training is: 0.8594713252305928 Accuracy for test is: 0.7639448977089842\n",
      "\n",
      "*For model 39 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 76 \n",
      "Accuracy for training is: 0.8562553374321221 Accuracy for test is: 0.7698912244219098\n",
      "\n",
      "*For model 40 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 78 \n",
      "Accuracy for training is: 0.8741837911231916 Accuracy for test is: 0.7802929383605057\n",
      "\n",
      "*For model 41 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 80 \n",
      "Accuracy for training is: 0.8710287833450377 Accuracy for test is: 0.748221450874504\n",
      "\n",
      "*For model 42 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 82 \n",
      "Accuracy for training is: 0.8783865316518835 Accuracy for test is: 0.7836649199901649\n",
      "\n",
      "*For model 43 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 84 \n",
      "Accuracy for training is: 0.8675274733909972 Accuracy for test is: 0.7683826418998823\n",
      "\n",
      "*For model 44 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 86 \n",
      "Accuracy for training is: 0.8641109837854881 Accuracy for test is: 0.7790528605719119\n",
      "\n",
      "*For model 45 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 88 \n",
      "Accuracy for training is: 0.8483910258673613 Accuracy for test is: 0.7860917893664114\n",
      "\n",
      "*For model 46 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 90 \n",
      "Accuracy for training is: 0.8677454407277543 Accuracy for test is: 0.7526334014990818\n",
      "\n",
      "*For model 47 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 92 \n",
      "Accuracy for training is: 0.8661656790206297 Accuracy for test is: 0.7561891998278165\n",
      "\n",
      "*For model 48 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 94 \n",
      "Accuracy for training is: 0.8504783106474249 Accuracy for test is: 0.7354036760793103\n",
      "\n",
      "*For model 49 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 96 \n",
      "Accuracy for training is: 0.8745392879337086 Accuracy for test is: 0.7894502737233821\n",
      "\n",
      "*For model 50 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.05 -random_state: 98 \n",
      "Accuracy for training is: 0.8785622841863369 Accuracy for test is: 0.7215366394092757\n",
      "\n",
      "*For model 51 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 0 \n",
      "Accuracy for training is: 0.835568019309193 Accuracy for test is: 0.7248256866300659\n",
      "\n",
      "*For model 52 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 2 \n",
      "Accuracy for training is: 0.8738531173511966 Accuracy for test is: 0.7499569304730369\n",
      "\n",
      "*For model 53 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 4 \n",
      "Accuracy for training is: 0.8911692958330601 Accuracy for test is: 0.7464695324685153\n",
      "\n",
      "*For model 54 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 6 \n",
      "Accuracy for training is: 0.8664549162531685 Accuracy for test is: 0.7763343706966064\n",
      "\n",
      "*For model 55 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 8 \n",
      "Accuracy for training is: 0.8856461754547508 Accuracy for test is: 0.7740158327149596\n",
      "\n",
      "*For model 56 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 10 \n",
      "Accuracy for training is: 0.8725466927712733 Accuracy for test is: 0.7695867280031975\n",
      "\n",
      "*For model 57 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 12 \n",
      "Accuracy for training is: 0.8683658873548674 Accuracy for test is: 0.7525157243589627\n",
      "\n",
      "*For model 58 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 14 \n",
      "Accuracy for training is: 0.8881244311222555 Accuracy for test is: 0.7433832867643109\n",
      "\n",
      "*For model 59 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 16 \n",
      "Accuracy for training is: 0.8947810779214558 Accuracy for test is: 0.7377056436316757\n",
      "\n",
      "*For model 60 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 18 \n",
      "Accuracy for training is: 0.85775877825063 Accuracy for test is: 0.7447812881848648\n",
      "\n",
      "*For model 61 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 20 \n",
      "Accuracy for training is: 0.8802332987256307 Accuracy for test is: 0.7765019789257667\n",
      "\n",
      "*For model 62 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 22 \n",
      "Accuracy for training is: 0.8905333785977216 Accuracy for test is: 0.755040947350986\n",
      "\n",
      "*For model 63 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 24 \n",
      "Accuracy for training is: 0.8858603957771 Accuracy for test is: 0.7555853077512639\n",
      "\n",
      "*For model 64 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 26 \n",
      "Accuracy for training is: 0.8728977728408243 Accuracy for test is: 0.7648789190175636\n",
      "\n",
      "*For model 65 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 28 \n",
      "Accuracy for training is: 0.8823773742311054 Accuracy for test is: 0.7630650679303296\n",
      "\n",
      "*For model 66 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 30 \n",
      "Accuracy for training is: 0.8519618259564306 Accuracy for test is: 0.7719630659514047\n",
      "\n",
      "*For model 67 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 32 \n",
      "Accuracy for training is: 0.8883039734047542 Accuracy for test is: 0.7573903606300525\n",
      "\n",
      "*For model 68 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 34 \n",
      "Accuracy for training is: 0.8600445703246902 Accuracy for test is: 0.7724978533516224\n",
      "\n",
      "*For model 69 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 36 \n",
      "Accuracy for training is: 0.8794598890504619 Accuracy for test is: 0.7550128700971073\n",
      "\n",
      "*For model 70 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 38 \n",
      "Accuracy for training is: 0.8655493930939042 Accuracy for test is: 0.7599143829093804\n",
      "\n",
      "*For model 71 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 40 \n",
      "Accuracy for training is: 0.8694651424927602 Accuracy for test is: 0.7567953008275077\n",
      "\n",
      "*For model 72 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 42 \n",
      "Accuracy for training is: 0.8906827490804796 Accuracy for test is: 0.7638715114297601\n",
      "\n",
      "*For model 73 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 44 \n",
      "Accuracy for training is: 0.8753742280374952 Accuracy for test is: 0.7698655340718004\n",
      "\n",
      "*For model 74 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 46 \n",
      "Accuracy for training is: 0.8815451997334575 Accuracy for test is: 0.7482291183941476\n",
      "\n",
      "*For model 75 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 48 \n",
      "Accuracy for training is: 0.8613950828488226 Accuracy for test is: 0.7362907050962277\n",
      "\n",
      "*For model 76 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 50 \n",
      "Accuracy for training is: 0.8704686217262962 Accuracy for test is: 0.7298937868214572\n",
      "\n",
      "*For model 77 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 52 \n",
      "Accuracy for training is: 0.8872492133398437 Accuracy for test is: 0.7403067153284345\n",
      "\n",
      "*For model 78 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 54 \n",
      "Accuracy for training is: 0.8754290738148423 Accuracy for test is: 0.7480692201075698\n",
      "\n",
      "*For model 79 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 56 \n",
      "Accuracy for training is: 0.8504915121507914 Accuracy for test is: 0.7355161746480086\n",
      "\n",
      "*For model 80 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 58 \n",
      "Accuracy for training is: 0.8638461117708724 Accuracy for test is: 0.7722476073685532\n",
      "\n",
      "*For model 81 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 60 \n",
      "Accuracy for training is: 0.8531124292636356 Accuracy for test is: 0.7295385658289031\n",
      "\n",
      "*For model 82 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 62 \n",
      "Accuracy for training is: 0.8795538725252491 Accuracy for test is: 0.7538207954429927\n",
      "\n",
      "*For model 83 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 64 \n",
      "Accuracy for training is: 0.8806568397093739 Accuracy for test is: 0.7380497204782128\n",
      "\n",
      "*For model 84 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 66 \n",
      "Accuracy for training is: 0.8516588866784907 Accuracy for test is: 0.7552007876943498\n",
      "\n",
      "*For model 85 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 68 \n",
      "Accuracy for training is: 0.8083637837588727 Accuracy for test is: 0.7172174836757748\n",
      "\n",
      "*For model 86 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 70 \n",
      "Accuracy for training is: 0.8726510734744719 Accuracy for test is: 0.7521684570403495\n",
      "\n",
      "*For model 87 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 72 \n",
      "Accuracy for training is: 0.8806185293964306 Accuracy for test is: 0.7591506055012229\n",
      "\n",
      "*For model 88 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 74 \n",
      "Accuracy for training is: 0.8761450459526874 Accuracy for test is: 0.7541556846135187\n",
      "\n",
      "*For model 89 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 76 \n",
      "Accuracy for training is: 0.8628042811811368 Accuracy for test is: 0.749994262148638\n",
      "\n",
      "*For model 90 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 78 \n",
      "Accuracy for training is: 0.8786608620241031 Accuracy for test is: 0.7561543265541603\n",
      "\n",
      "*For model 91 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 80 \n",
      "Accuracy for training is: 0.8556175064091995 Accuracy for test is: 0.7205251059552762\n",
      "\n",
      "*For model 92 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 82 \n",
      "Accuracy for training is: 0.87589514981502 Accuracy for test is: 0.7777091669186982\n",
      "\n",
      "*For model 93 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 84 \n",
      "Accuracy for training is: 0.8819044953854481 Accuracy for test is: 0.7421005763758304\n",
      "\n",
      "*For model 94 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 86 \n",
      "Accuracy for training is: 0.8771167434563647 Accuracy for test is: 0.7639840363578847\n",
      "\n",
      "*For model 95 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 88 \n",
      "Accuracy for training is: 0.8751806902241857 Accuracy for test is: 0.7552905487272794\n",
      "\n",
      "*For model 96 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 90 \n",
      "Accuracy for training is: 0.8773167597941623 Accuracy for test is: 0.7798157411013851\n",
      "\n",
      "*For model 97 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 92 \n",
      "Accuracy for training is: 0.874849686654339 Accuracy for test is: 0.7315860879970613\n",
      "\n",
      "*For model 98 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 94 \n",
      "Accuracy for training is: 0.8785842808910724 Accuracy for test is: 0.7353946014796677\n",
      "\n",
      "*For model 99 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 96 \n",
      "Accuracy for training is: 0.8715925579196877 Accuracy for test is: 0.7532654195418427\n",
      "\n",
      "*For model 100 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 10 -activation: relu -regularization cost: 1.0 -random_state: 98 \n",
      "Accuracy for training is: 0.8751594272876857 Accuracy for test is: 0.6966239874402397\n",
      "\n",
      "*For model 101 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 0 \n",
      "Accuracy for training is: 0.8432598866019256 Accuracy for test is: 0.7929606656052056\n",
      "\n",
      "*For model 102 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 2 \n",
      "Accuracy for training is: 0.8281314814794594 Accuracy for test is: 0.7840577392929051\n",
      "\n",
      "*For model 103 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 4 \n",
      "Accuracy for training is: 0.8437122272836184 Accuracy for test is: 0.762097673620764\n",
      "\n",
      "*For model 104 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 6 \n",
      "Accuracy for training is: 0.8345915450676434 Accuracy for test is: 0.7952786981324156\n",
      "\n",
      "*For model 105 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 8 \n",
      "Accuracy for training is: 0.8132378066520184 Accuracy for test is: 0.7800508589822296\n",
      "\n",
      "*For model 106 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 10 \n",
      "Accuracy for training is: 0.8283862560782478 Accuracy for test is: 0.7907187314411178\n",
      "\n",
      "*For model 107 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 12 \n",
      "Accuracy for training is: 0.8381294780335937 Accuracy for test is: 0.7846316463689308\n",
      "\n",
      "*For model 108 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 14 \n",
      "Accuracy for training is: 0.8527401646575581 Accuracy for test is: 0.7878612387697506\n",
      "\n",
      "*For model 109 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 16 \n",
      "Accuracy for training is: 0.8386501950896287 Accuracy for test is: 0.7887941029409845\n",
      "\n",
      "*For model 110 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 18 \n",
      "Accuracy for training is: 0.8384481530517646 Accuracy for test is: 0.7977449218247764\n",
      "\n",
      "*For model 111 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 20 \n",
      "Accuracy for training is: 0.8362847852777539 Accuracy for test is: 0.8008035258341056\n",
      "\n",
      "*For model 112 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 22 \n",
      "Accuracy for training is: 0.8453717370032477 Accuracy for test is: 0.7755955304481955\n",
      "\n",
      "*For model 113 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 24 \n",
      "Accuracy for training is: 0.8321505648412992 Accuracy for test is: 0.7936454455913917\n",
      "\n",
      "*For model 114 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 26 \n",
      "Accuracy for training is: 0.8397969421812231 Accuracy for test is: 0.8023823049587154\n",
      "\n",
      "*For model 115 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 28 \n",
      "Accuracy for training is: 0.84714850807594 Accuracy for test is: 0.792358665722874\n",
      "\n",
      "*For model 116 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 30 \n",
      "Accuracy for training is: 0.8316351530632943 Accuracy for test is: 0.7943719232347286\n",
      "\n",
      "*For model 117 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 32 \n",
      "Accuracy for training is: 0.8311518586735829 Accuracy for test is: 0.7738034588566783\n",
      "\n",
      "*For model 118 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 34 \n",
      "Accuracy for training is: 0.843381682181631 Accuracy for test is: 0.7892566948199208\n",
      "\n",
      "*For model 119 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 36 \n",
      "Accuracy for training is: 0.8287733444379279 Accuracy for test is: 0.7760948922117679\n",
      "\n",
      "*For model 120 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 38 \n",
      "Accuracy for training is: 0.8440415546696555 Accuracy for test is: 0.7757661535232386\n",
      "\n",
      "*For model 121 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 40 \n",
      "Accuracy for training is: 0.8400532506776477 Accuracy for test is: 0.7847617868363841\n",
      "\n",
      "*For model 122 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 42 \n",
      "Accuracy for training is: 0.8159095789365065 Accuracy for test is: 0.7680583680878605\n",
      "\n",
      "*For model 123 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 44 \n",
      "Accuracy for training is: 0.8336292611414649 Accuracy for test is: 0.7809996195788222\n",
      "\n",
      "*For model 124 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 46 \n",
      "Accuracy for training is: 0.8119251045647299 Accuracy for test is: 0.7412736059318756\n",
      "\n",
      "*For model 125 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 48 \n",
      "Accuracy for training is: 0.8396932472827808 Accuracy for test is: 0.7797611547229115\n",
      "\n",
      "*For model 126 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 50 \n",
      "Accuracy for training is: 0.8450473308999484 Accuracy for test is: 0.7999331273558885\n",
      "\n",
      "*For model 127 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 52 \n",
      "Accuracy for training is: 0.8320900084954082 Accuracy for test is: 0.7716347643353648\n",
      "\n",
      "*For model 128 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 54 \n",
      "Accuracy for training is: 0.8284806841355795 Accuracy for test is: 0.7766866359330322\n",
      "\n",
      "*For model 129 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 56 \n",
      "Accuracy for training is: 0.8433624958256052 Accuracy for test is: 0.7795075582724864\n",
      "\n",
      "*For model 130 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 58 \n",
      "Accuracy for training is: 0.8388117778277178 Accuracy for test is: 0.793228225182933\n",
      "\n",
      "*For model 131 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 60 \n",
      "Accuracy for training is: 0.8326800811465446 Accuracy for test is: 0.7836569808246673\n",
      "\n",
      "*For model 132 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 62 \n",
      "Accuracy for training is: 0.857592745076811 Accuracy for test is: 0.7623213649027337\n",
      "\n",
      "*For model 133 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 64 \n",
      "Accuracy for training is: 0.8024591268745493 Accuracy for test is: 0.7397002511445616\n",
      "\n",
      "*For model 134 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 66 \n",
      "Accuracy for training is: 0.8334478991659813 Accuracy for test is: 0.7884208205615854\n",
      "\n",
      "*For model 135 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 68 \n",
      "Accuracy for training is: 0.820700565042378 Accuracy for test is: 0.776735145229655\n",
      "\n",
      "*For model 136 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 70 \n",
      "Accuracy for training is: 0.8513420764349526 Accuracy for test is: 0.7856310747542262\n",
      "\n",
      "*For model 137 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 72 \n",
      "Accuracy for training is: 0.8380507106658326 Accuracy for test is: 0.7904646543448297\n",
      "\n",
      "*For model 138 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 74 \n",
      "Accuracy for training is: 0.8368555832687574 Accuracy for test is: 0.7791679605453018\n",
      "\n",
      "*For model 139 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 76 \n",
      "Accuracy for training is: 0.8339384485060424 Accuracy for test is: 0.7866838644743054\n",
      "\n",
      "*For model 140 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 78 \n",
      "Accuracy for training is: 0.824295525766154 Accuracy for test is: 0.7902159917309058\n",
      "\n",
      "*For model 141 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 80 \n",
      "Accuracy for training is: 0.8380877112029811 Accuracy for test is: 0.7682620222000844\n",
      "\n",
      "*For model 142 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 82 \n",
      "Accuracy for training is: 0.8332577471481873 Accuracy for test is: 0.8030428736667203\n",
      "\n",
      "*For model 143 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 84 \n",
      "Accuracy for training is: 0.8431082908963137 Accuracy for test is: 0.7782568818036228\n",
      "\n",
      "*For model 144 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 86 \n",
      "Accuracy for training is: 0.8339884613031089 Accuracy for test is: 0.79029342444393\n",
      "\n",
      "*For model 145 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 88 \n",
      "Accuracy for training is: 0.8390563062052785 Accuracy for test is: 0.7846704908965666\n",
      "\n",
      "*For model 146 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 90 \n",
      "Accuracy for training is: 0.83943400607666 Accuracy for test is: 0.7861527128462052\n",
      "\n",
      "*For model 147 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 92 \n",
      "Accuracy for training is: 0.8287633259681706 Accuracy for test is: 0.7569676612826316\n",
      "\n",
      "*For model 148 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 94 \n",
      "Accuracy for training is: 0.8265422095234614 Accuracy for test is: 0.759077060628318\n",
      "\n",
      "*For model 149 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 96 \n",
      "Accuracy for training is: 0.8347197665316255 Accuracy for test is: 0.80841200912957\n",
      "\n",
      "*For model 150 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 5 -activation: relu -regularization cost: 0.1 -random_state: 98 \n",
      "Accuracy for training is: 0.8375414188001434 Accuracy for test is: 0.7455441090151503\n",
      "\n",
      "*For model 151 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 0 \n",
      "Accuracy for training is: 0.8203592189602998 Accuracy for test is: 0.784429217215721\n",
      "\n",
      "*For model 152 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 2 \n",
      "Accuracy for training is: 0.829953585489734 Accuracy for test is: 0.779399146390689\n",
      "\n",
      "*For model 153 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 4 \n",
      "Accuracy for training is: 0.8407016127726642 Accuracy for test is: 0.759416312325195\n",
      "\n",
      "*For model 154 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 6 \n",
      "Accuracy for training is: 0.8301996210461866 Accuracy for test is: 0.7763845246827946\n",
      "\n",
      "*For model 155 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 8 \n",
      "Accuracy for training is: 0.8271114630683113 Accuracy for test is: 0.7978656891755923\n",
      "\n",
      "*For model 156 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 10 \n",
      "Accuracy for training is: 0.8316282739317858 Accuracy for test is: 0.7823062296715912\n",
      "\n",
      "*For model 157 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 12 \n",
      "Accuracy for training is: 0.8239241969224336 Accuracy for test is: 0.779768917644827\n",
      "\n",
      "*For model 158 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 14 \n",
      "Accuracy for training is: 0.8376067280003469 Accuracy for test is: 0.78833670354032\n",
      "\n",
      "*For model 159 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 16 \n",
      "Accuracy for training is: 0.8346316631011085 Accuracy for test is: 0.7859119037166541\n",
      "\n",
      "*For model 160 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 18 \n",
      "Accuracy for training is: 0.8513041959164415 Accuracy for test is: 0.7971502720967585\n",
      "\n",
      "*For model 161 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 20 \n",
      "Accuracy for training is: 0.8249196122417424 Accuracy for test is: 0.7607834944805503\n",
      "\n",
      "*For model 162 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 22 \n",
      "Accuracy for training is: 0.8401457247659536 Accuracy for test is: 0.7743471583713625\n",
      "\n",
      "*For model 163 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 24 \n",
      "Accuracy for training is: 0.8397660735615171 Accuracy for test is: 0.7971400752704226\n",
      "\n",
      "*For model 164 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 26 \n",
      "Accuracy for training is: 0.8291379369395891 Accuracy for test is: 0.8003785577349602\n",
      "\n",
      "*For model 165 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 28 \n",
      "Accuracy for training is: 0.8348945641427473 Accuracy for test is: 0.7905498646007431\n",
      "\n",
      "*For model 166 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 30 \n",
      "Accuracy for training is: 0.8359484903122696 Accuracy for test is: 0.7929180917893801\n",
      "\n",
      "*For model 167 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 32 \n",
      "Accuracy for training is: 0.832494955911181 Accuracy for test is: 0.7825013843203169\n",
      "\n",
      "*For model 168 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 34 \n",
      "Accuracy for training is: 0.842025783052053 Accuracy for test is: 0.7811009694317264\n",
      "\n",
      "*For model 169 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 36 \n",
      "Accuracy for training is: 0.8441333918830016 Accuracy for test is: 0.7718138455094553\n",
      "\n",
      "*For model 170 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 38 \n",
      "Accuracy for training is: 0.8299657240048326 Accuracy for test is: 0.7674688356820254\n",
      "\n",
      "*For model 171 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 40 \n",
      "Accuracy for training is: 0.8306350983018592 Accuracy for test is: 0.7915394978691475\n",
      "\n",
      "*For model 172 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 42 \n",
      "Accuracy for training is: 0.838101460652808 Accuracy for test is: 0.7820837324303276\n",
      "\n",
      "*For model 173 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 44 \n",
      "Accuracy for training is: 0.8384326252454006 Accuracy for test is: 0.7858354243317248\n",
      "\n",
      "*For model 174 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 46 \n",
      "Accuracy for training is: 0.8274128448973437 Accuracy for test is: 0.7667455911247343\n",
      "\n",
      "*For model 175 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 48 \n",
      "Accuracy for training is: 0.8429697928604527 Accuracy for test is: 0.777362868799508\n",
      "\n",
      "*For model 176 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 50 \n",
      "Accuracy for training is: 0.83815519317938 Accuracy for test is: 0.790118928722178\n",
      "\n",
      "*For model 177 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 52 \n",
      "Accuracy for training is: 0.8386886512048926 Accuracy for test is: 0.7741630810021884\n",
      "\n",
      "*For model 178 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 54 \n",
      "Accuracy for training is: 0.8173911984299624 Accuracy for test is: 0.7845263776350015\n",
      "\n",
      "*For model 179 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 56 \n",
      "Accuracy for training is: 0.8170632224216515 Accuracy for test is: 0.7460068450749282\n",
      "\n",
      "*For model 180 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 58 \n",
      "Accuracy for training is: 0.8299126256171543 Accuracy for test is: 0.797636090445957\n",
      "\n",
      "*For model 181 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 60 \n",
      "Accuracy for training is: 0.8365553315530647 Accuracy for test is: 0.784958886058138\n",
      "\n",
      "*For model 182 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 62 \n",
      "Accuracy for training is: 0.8318374224420889 Accuracy for test is: 0.7606748723714865\n",
      "\n",
      "*For model 183 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 64 \n",
      "Accuracy for training is: 0.8334548239963608 Accuracy for test is: 0.7832552629816667\n",
      "\n",
      "*For model 184 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 66 \n",
      "Accuracy for training is: 0.8374083343669526 Accuracy for test is: 0.7867748713059916\n",
      "\n",
      "*For model 185 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 68 \n",
      "Accuracy for training is: 0.8410196661532413 Accuracy for test is: 0.791796440940716\n",
      "\n",
      "*For model 186 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 70 \n",
      "Accuracy for training is: 0.8139747460708706 Accuracy for test is: 0.7601624612400195\n",
      "\n",
      "*For model 187 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 72 \n",
      "Accuracy for training is: 0.8168866214712696 Accuracy for test is: 0.7684826562820711\n",
      "\n",
      "*For model 188 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 74 \n",
      "Accuracy for training is: 0.8098984035368686 Accuracy for test is: 0.7360923651511038\n",
      "\n",
      "*For model 189 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 76 \n",
      "Accuracy for training is: 0.8157308698341906 Accuracy for test is: 0.7672705219701027\n",
      "\n",
      "*For model 190 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 78 \n",
      "Accuracy for training is: 0.8462286147025813 Accuracy for test is: 0.787347956704476\n",
      "\n",
      "*For model 191 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 80 \n",
      "Accuracy for training is: 0.8412155119134643 Accuracy for test is: 0.7639692369820126\n",
      "\n",
      "*For model 192 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 82 \n",
      "Accuracy for training is: 0.8389104312581382 Accuracy for test is: 0.7993759122395052\n",
      "\n",
      "*For model 193 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 84 \n",
      "Accuracy for training is: 0.8243450169721627 Accuracy for test is: 0.7473680616831729\n",
      "\n",
      "*For model 194 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 86 \n",
      "Accuracy for training is: 0.8400911765360084 Accuracy for test is: 0.7776207092312555\n",
      "\n",
      "*For model 195 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 88 \n",
      "Accuracy for training is: 0.8375363725686712 Accuracy for test is: 0.7890731062707087\n",
      "\n",
      "*For model 196 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 90 \n",
      "Accuracy for training is: 0.8349075167751874 Accuracy for test is: 0.7746408396461741\n",
      "\n",
      "*For model 197 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 92 \n",
      "Accuracy for training is: 0.8430762738421731 Accuracy for test is: 0.7697639248506427\n",
      "\n",
      "*For model 198 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 94 \n",
      "Accuracy for training is: 0.8490387356102007 Accuracy for test is: 0.7729239647635062\n",
      "\n",
      "*For model 199 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 96 \n",
      "Accuracy for training is: 0.8323584695033104 Accuracy for test is: 0.7890850837657796\n",
      "\n",
      "*For model 200 settings are: -epochs: 100 -hidden neurons: 75 -hidden layers: 6 -activation: relu -regularization cost: 0.75 -random_state: 98 \n",
      "Accuracy for training is: 0.8483311231814651 Accuracy for test is: 0.7476850009517395\n",
      "\n",
      "*For model 201 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 0 \n",
      "Accuracy for training is: 0.879522704764461 Accuracy for test is: 0.7584375670156525\n",
      "\n",
      "*For model 202 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 2 \n",
      "Accuracy for training is: 0.8757153268872951 Accuracy for test is: 0.7630255860539555\n",
      "\n",
      "*For model 203 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 4 \n",
      "Accuracy for training is: 0.8866358895836298 Accuracy for test is: 0.7376123336452708\n",
      "\n",
      "*For model 204 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 6 \n",
      "Accuracy for training is: 0.8644489298884371 Accuracy for test is: 0.7623304035932328\n",
      "\n",
      "*For model 205 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 8 \n",
      "Accuracy for training is: 0.8686345690901704 Accuracy for test is: 0.781799241627115\n",
      "\n",
      "*For model 206 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 10 \n",
      "Accuracy for training is: 0.8755559076410547 Accuracy for test is: 0.7537281720116644\n",
      "\n",
      "*For model 207 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 12 \n",
      "Accuracy for training is: 0.8734741583454455 Accuracy for test is: 0.7635102292027324\n",
      "\n",
      "*For model 208 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 14 \n",
      "Accuracy for training is: 0.8704661003801761 Accuracy for test is: 0.7603469205874066\n",
      "\n",
      "*For model 209 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 16 \n",
      "Accuracy for training is: 0.8700666991061476 Accuracy for test is: 0.7524289791954927\n",
      "\n",
      "*For model 210 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 18 \n",
      "Accuracy for training is: 0.8810970345196286 Accuracy for test is: 0.745164219569167\n",
      "\n",
      "*For model 211 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 20 \n",
      "Accuracy for training is: 0.85532326721805 Accuracy for test is: 0.7593126214101018\n",
      "\n",
      "*For model 212 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 22 \n",
      "Accuracy for training is: 0.8721405094680499 Accuracy for test is: 0.7508444140720587\n",
      "\n",
      "*For model 213 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 24 \n",
      "Accuracy for training is: 0.8740055853670534 Accuracy for test is: 0.7620743208394638\n",
      "\n",
      "*For model 214 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 26 \n",
      "Accuracy for training is: 0.8723315987677405 Accuracy for test is: 0.7560134173260261\n",
      "\n",
      "*For model 215 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 28 \n",
      "Accuracy for training is: 0.8698124116596595 Accuracy for test is: 0.7675190994746596\n",
      "\n",
      "*For model 216 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 30 \n",
      "Accuracy for training is: 0.869110515082952 Accuracy for test is: 0.7462290643062933\n",
      "\n",
      "*For model 217 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 32 \n",
      "Accuracy for training is: 0.8773743484787119 Accuracy for test is: 0.7740487290588101\n",
      "\n",
      "*For model 218 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 34 \n",
      "Accuracy for training is: 0.8672694309539233 Accuracy for test is: 0.7638651767883042\n",
      "\n",
      "*For model 219 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 36 \n",
      "Accuracy for training is: 0.8747521791461467 Accuracy for test is: 0.7571725027081635\n",
      "\n",
      "*For model 220 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 38 \n",
      "Accuracy for training is: 0.872988285378695 Accuracy for test is: 0.7408137164411428\n",
      "\n",
      "*For model 221 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 40 \n",
      "Accuracy for training is: 0.8687407221469158 Accuracy for test is: 0.7713472974490554\n",
      "\n",
      "*For model 222 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 42 \n",
      "Accuracy for training is: 0.8808160473977346 Accuracy for test is: 0.7688140372358632\n",
      "\n",
      "*For model 223 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 44 \n",
      "Accuracy for training is: 0.8702897303806862 Accuracy for test is: 0.7636226372128998\n",
      "\n",
      "*For model 224 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 46 \n",
      "Accuracy for training is: 0.8397318472374161 Accuracy for test is: 0.7213985168022979\n",
      "\n",
      "*For model 225 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 48 \n",
      "Accuracy for training is: 0.8828538191119641 Accuracy for test is: 0.7508500619578821\n",
      "\n",
      "*For model 226 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 50 \n",
      "Accuracy for training is: 0.8465347694156167 Accuracy for test is: 0.7282596148069123\n",
      "\n",
      "*For model 227 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 52 \n",
      "Accuracy for training is: 0.8643700003413984 Accuracy for test is: 0.7534379516284857\n",
      "\n",
      "*For model 228 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 54 \n",
      "Accuracy for training is: 0.8805088233003353 Accuracy for test is: 0.7621556566537485\n",
      "\n",
      "*For model 229 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 56 \n",
      "Accuracy for training is: 0.8680099864722721 Accuracy for test is: 0.7376242863174847\n",
      "\n",
      "*For model 230 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 58 \n",
      "Accuracy for training is: 0.8777473697067878 Accuracy for test is: 0.7609662234662162\n",
      "\n",
      "*For model 231 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 60 \n",
      "Accuracy for training is: 0.8705252804348309 Accuracy for test is: 0.7359822308474323\n",
      "\n",
      "*For model 232 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 62 \n",
      "Accuracy for training is: 0.8786715892185933 Accuracy for test is: 0.7392845960837933\n",
      "\n",
      "*For model 233 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 64 \n",
      "Accuracy for training is: 0.8641607307468546 Accuracy for test is: 0.7473505331915014\n",
      "\n",
      "*For model 234 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 66 \n",
      "Accuracy for training is: 0.8724661219864499 Accuracy for test is: 0.7599460291840845\n",
      "\n",
      "*For model 235 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 68 \n",
      "Accuracy for training is: 0.8693633604806318 Accuracy for test is: 0.7658494929584141\n",
      "\n",
      "*For model 236 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 70 \n",
      "Accuracy for training is: 0.8660978952600518 Accuracy for test is: 0.7600938209863684\n",
      "\n",
      "*For model 237 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 72 \n",
      "Accuracy for training is: 0.8671553756448769 Accuracy for test is: 0.758720595926774\n",
      "\n",
      "*For model 238 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 74 \n",
      "Accuracy for training is: 0.8857864567943502 Accuracy for test is: 0.75524345792981\n",
      "\n",
      "*For model 239 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 76 \n",
      "Accuracy for training is: 0.8777699154289333 Accuracy for test is: 0.750899786933888\n",
      "\n",
      "*For model 240 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 78 \n",
      "Accuracy for training is: 0.877122347233307 Accuracy for test is: 0.7550439143818943\n",
      "\n",
      "*For model 241 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 80 \n",
      "Accuracy for training is: 0.8796549928399382 Accuracy for test is: 0.7519087422049501\n",
      "\n",
      "*For model 242 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 82 \n",
      "Accuracy for training is: 0.878019891559959 Accuracy for test is: 0.7746140877317962\n",
      "\n",
      "*For model 243 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 84 \n",
      "Accuracy for training is: 0.8863155838316312 Accuracy for test is: 0.741574423622555\n",
      "\n",
      "*For model 244 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 86 \n",
      "Accuracy for training is: 0.884542277012524 Accuracy for test is: 0.7473153099100851\n",
      "\n",
      "*For model 245 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 88 \n",
      "Accuracy for training is: 0.889333495608401 Accuracy for test is: 0.7688316489852189\n",
      "\n",
      "*For model 246 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 90 \n",
      "Accuracy for training is: 0.8729850288377333 Accuracy for test is: 0.7348174240312495\n",
      "\n",
      "*For model 247 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 92 \n",
      "Accuracy for training is: 0.874377570351605 Accuracy for test is: 0.7449025221089041\n",
      "\n",
      "*For model 248 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 94 \n",
      "Accuracy for training is: 0.8724318749070005 Accuracy for test is: 0.7558555879226759\n",
      "\n",
      "*For model 249 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 96 \n",
      "Accuracy for training is: 0.880246833467834 Accuracy for test is: 0.7785237254609958\n",
      "\n",
      "*For model 250 settings are: -epochs: 200 -hidden neurons: 100 -hidden layers: 6 -activation: relu -regularization cost: 0.05 -random_state: 98 \n",
      "Accuracy for training is: 0.8749838312926729 Accuracy for test is: 0.7253970363225114\n",
      "\n",
      "*For model 251 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 0 \n",
      "Accuracy for training is: 0.8381119828656662 Accuracy for test is: 0.7895002372610821\n",
      "\n",
      "*For model 252 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 2 \n",
      "Accuracy for training is: 0.8261357826084424 Accuracy for test is: 0.7829360833030032\n",
      "\n",
      "*For model 253 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 4 \n",
      "Accuracy for training is: 0.8375780981104747 Accuracy for test is: 0.7815757770150342\n",
      "\n",
      "*For model 254 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 6 \n",
      "Accuracy for training is: 0.8515779451650206 Accuracy for test is: 0.8034331870601908\n",
      "\n",
      "*For model 255 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 8 \n",
      "Accuracy for training is: 0.8485661176801089 Accuracy for test is: 0.8081058066672135\n",
      "\n",
      "*For model 256 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 10 \n",
      "Accuracy for training is: 0.836466179272884 Accuracy for test is: 0.7879909056596084\n",
      "\n",
      "*For model 257 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 12 \n",
      "Accuracy for training is: 0.8380091843278517 Accuracy for test is: 0.7876213472485456\n",
      "\n",
      "*For model 258 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 14 \n",
      "Accuracy for training is: 0.8438732692139777 Accuracy for test is: 0.7709142390920398\n",
      "\n",
      "*For model 259 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 16 \n",
      "Accuracy for training is: 0.8287553612072682 Accuracy for test is: 0.7662489647429063\n",
      "\n",
      "*For model 260 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 18 \n",
      "Accuracy for training is: 0.8472044979758669 Accuracy for test is: 0.7921245638184506\n",
      "\n",
      "*For model 261 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 20 \n",
      "Accuracy for training is: 0.8441462405672513 Accuracy for test is: 0.7977101609950166\n",
      "\n",
      "*For model 262 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 22 \n",
      "Accuracy for training is: 0.8387009976486014 Accuracy for test is: 0.7717116471673312\n",
      "\n",
      "*For model 263 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 24 \n",
      "Accuracy for training is: 0.8345155019400179 Accuracy for test is: 0.7961112953708849\n",
      "\n",
      "*For model 264 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 26 \n",
      "Accuracy for training is: 0.8407712050270197 Accuracy for test is: 0.7869392447890352\n",
      "\n",
      "*For model 265 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 28 \n",
      "Accuracy for training is: 0.833819013865234 Accuracy for test is: 0.7875334566563572\n",
      "\n",
      "*For model 266 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 30 \n",
      "Accuracy for training is: 0.8228579089873862 Accuracy for test is: 0.7830693373803954\n",
      "\n",
      "*For model 267 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 32 \n",
      "Accuracy for training is: 0.8322866233025207 Accuracy for test is: 0.7755275376785589\n",
      "\n",
      "*For model 268 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 34 \n",
      "Accuracy for training is: 0.8247376117059911 Accuracy for test is: 0.7638134157204048\n",
      "\n",
      "*For model 269 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 36 \n",
      "Accuracy for training is: 0.840538796070865 Accuracy for test is: 0.7684828156136223\n",
      "\n",
      "*For model 270 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 38 \n",
      "Accuracy for training is: 0.8325364236886508 Accuracy for test is: 0.7707498113554109\n",
      "\n",
      "*For model 271 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 40 \n",
      "Accuracy for training is: 0.8425010924506409 Accuracy for test is: 0.7999098678949054\n",
      "\n",
      "*For model 272 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 42 \n",
      "Accuracy for training is: 0.8367075861082722 Accuracy for test is: 0.7926749617766282\n",
      "\n",
      "*For model 273 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 44 \n",
      "Accuracy for training is: 0.825950289282196 Accuracy for test is: 0.7845548239802821\n",
      "\n",
      "*For model 274 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 46 \n",
      "Accuracy for training is: 0.8420700809699659 Accuracy for test is: 0.7853661924161555\n",
      "\n",
      "*For model 275 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 48 \n",
      "Accuracy for training is: 0.8460528847927464 Accuracy for test is: 0.7822524266379268\n",
      "\n",
      "*For model 276 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 50 \n",
      "Accuracy for training is: 0.8370168730149342 Accuracy for test is: 0.7833433551036959\n",
      "\n",
      "*For model 277 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 52 \n",
      "Accuracy for training is: 0.8362719745229462 Accuracy for test is: 0.7733406080029427\n",
      "\n",
      "*For model 278 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 54 \n",
      "Accuracy for training is: 0.8406968977795833 Accuracy for test is: 0.7737129659084134\n",
      "\n",
      "*For model 279 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 56 \n",
      "Accuracy for training is: 0.8434398475147691 Accuracy for test is: 0.7747925975275824\n",
      "\n",
      "*For model 280 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 58 \n",
      "Accuracy for training is: 0.8412609309549164 Accuracy for test is: 0.7903627913746322\n",
      "\n",
      "*For model 281 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 60 \n",
      "Accuracy for training is: 0.83616129716855 Accuracy for test is: 0.7732194496432994\n",
      "\n",
      "*For model 282 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 62 \n",
      "Accuracy for training is: 0.8453198485819051 Accuracy for test is: 0.7667542738443632\n",
      "\n",
      "*For model 283 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 64 \n",
      "Accuracy for training is: 0.8338422309191538 Accuracy for test is: 0.7909789114655245\n",
      "\n",
      "*For model 284 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 66 \n",
      "Accuracy for training is: 0.8388212930294481 Accuracy for test is: 0.7930468343208839\n",
      "\n",
      "*For model 285 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 68 \n",
      "Accuracy for training is: 0.8297027750519492 Accuracy for test is: 0.7895343675940322\n",
      "\n",
      "*For model 286 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 70 \n",
      "Accuracy for training is: 0.8408609679732807 Accuracy for test is: 0.785178047228585\n",
      "\n",
      "*For model 287 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 72 \n",
      "Accuracy for training is: 0.8230134869625354 Accuracy for test is: 0.789830196979287\n",
      "\n",
      "*For model 288 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 74 \n",
      "Accuracy for training is: 0.8431637696258403 Accuracy for test is: 0.7736516224037787\n",
      "\n",
      "*For model 289 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 76 \n",
      "Accuracy for training is: 0.8324504135458511 Accuracy for test is: 0.7873363076100227\n",
      "\n",
      "*For model 290 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 78 \n",
      "Accuracy for training is: 0.8294064542502813 Accuracy for test is: 0.7870604153437779\n",
      "\n",
      "*For model 291 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 80 \n",
      "Accuracy for training is: 0.8458709471876604 Accuracy for test is: 0.7629577517313199\n",
      "\n",
      "*For model 292 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 82 \n",
      "Accuracy for training is: 0.8362004395660165 Accuracy for test is: 0.7945743573649895\n",
      "\n",
      "*For model 293 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 84 \n",
      "Accuracy for training is: 0.8223271833874749 Accuracy for test is: 0.7804659863822895\n",
      "\n",
      "*For model 294 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 86 \n",
      "Accuracy for training is: 0.8452909394288411 Accuracy for test is: 0.7879899712248395\n",
      "\n",
      "*For model 295 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 88 \n",
      "Accuracy for training is: 0.8353099874831317 Accuracy for test is: 0.7823054722604424\n",
      "\n",
      "*For model 296 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 90 \n",
      "Accuracy for training is: 0.838111086781256 Accuracy for test is: 0.7698188579906796\n",
      "\n",
      "*For model 297 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 92 \n",
      "Accuracy for training is: 0.8481622743389251 Accuracy for test is: 0.7737442160543819\n",
      "\n",
      "*For model 298 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 94 \n",
      "Accuracy for training is: 0.8227598669593985 Accuracy for test is: 0.7731216327807827\n",
      "\n",
      "*For model 299 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 96 \n",
      "Accuracy for training is: 0.8342009218594086 Accuracy for test is: 0.7966552784814821\n",
      "\n",
      "*For model 300 settings are: -epochs: 100 -hidden neurons: 100 -hidden layers: 3 -activation: relu -regularization cost: 0.1 -random_state: 98 \n",
      "Accuracy for training is: 0.8365603592048515 Accuracy for test is: 0.742176240379522\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "bm = list(df_bestmodels.model.unique())\n",
    "\n",
    "models = {}\n",
    "\n",
    "rndm = range(0,100,2)\n",
    "\n",
    "for mn in bm:\n",
    "    nh = int(nn.loc[nn.model_number==mn,'hidden_neurons'])\n",
    "    hl = int(nn.loc[nn.model_number==mn,'hidden_layers'])\n",
    "    e = int(nn.loc[nn.model_number==mn,'epochs'])\n",
    "    a = 'relu'\n",
    "    r = float(nn.loc[nn.model_number==mn,'regularization'])\n",
    "\n",
    "    for rnd_st in rndm:\n",
    "\n",
    "        X_train,X_test,Y_train,Y_test = train_test_split(X, Y, \n",
    "                                                         test_size = 0.2, \n",
    "                                                         random_state=rnd_st) #split\n",
    "\n",
    "        model = neuron_layers(10,nh,1,hl,a,r,1)\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "\n",
    "        history = model.fit(X_train, Y_train, epochs=e, \n",
    "                            batch_size=50,  verbose=0, validation_split=0.2)\n",
    "\n",
    "        #statistics for train\n",
    "        y_hat= model.predict(X_train)\n",
    "        acc_train = r2_score(Y_train, y_hat)\n",
    "        mse_train = mean_squared_error(Y_train, y_hat)\n",
    "        mae_train = mean_absolute_error(Y_train, y_hat)\n",
    "        rmse_train = mean_squared_error(Y_train, y_hat, squared=False)\n",
    "\n",
    "        num_train = ((y_hat - Y_train)**2).sum()\n",
    "        den_train = ((abs(y_hat - Y_train.mean()) + \n",
    "                abs(Y_train - Y_train.mean()))**2).sum()\n",
    "        ia_train = round(1 - (num_train / den_train),3)\n",
    "\n",
    "        #statistics for test\n",
    "        y_hat = model.predict(X_test)\n",
    "        acc_test = r2_score(Y_test, y_hat)\n",
    "        mse_test = mean_squared_error(Y_test, y_hat)\n",
    "        mae_test = mean_absolute_error(Y_test, y_hat)\n",
    "        rmse_test = mean_squared_error(Y_test, y_hat, squared=False)\n",
    "\n",
    "        num_test = ((y_hat - Y_test)**2).sum()\n",
    "        den_test = ((abs(y_hat - Y_test.mean()) + \n",
    "                abs(Y_test - Y_test.mean()))**2).sum()\n",
    "        ia_test = round(1 - (num_test / den_test),3)\n",
    "\n",
    "        models['model'+str(i)] = [mn, e, nh, hl, a, r, rnd_st,\n",
    "                                               acc_train, mse_train, mae_train, rmse_train, ia_train,\n",
    "                                               acc_test, mse_test, mae_test, rmse_test, ia_test]\n",
    "\n",
    "        print ('\\n*For model',str(i),'settings are:','-epochs:',str(e),'-hidden neurons:',str(nh),'-hidden layers:',str(hl),'-activation:',a,\n",
    "               '-regularization cost:',r,'-random_state:',rnd_st,\n",
    "               '\\nAccuracy for training is:', str(acc_train),'Accuracy for test is:',str(acc_test))\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>model5</th>\n",
       "      <th>model6</th>\n",
       "      <th>model7</th>\n",
       "      <th>model8</th>\n",
       "      <th>model9</th>\n",
       "      <th>model10</th>\n",
       "      <th>...</th>\n",
       "      <th>model291</th>\n",
       "      <th>model292</th>\n",
       "      <th>model293</th>\n",
       "      <th>model294</th>\n",
       "      <th>model295</th>\n",
       "      <th>model296</th>\n",
       "      <th>model297</th>\n",
       "      <th>model298</th>\n",
       "      <th>model299</th>\n",
       "      <th>model300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>model1209</td>\n",
       "      <td>...</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "      <td>model788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>...</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model1     model2     model3     model4     model5     model6  \\\n",
       "0  model1209  model1209  model1209  model1209  model1209  model1209   \n",
       "1        200        200        200        200        200        200   \n",
       "2        100        100        100        100        100        100   \n",
       "3          3          3          3          3          3          3   \n",
       "4       relu       relu       relu       relu       relu       relu   \n",
       "\n",
       "      model7     model8     model9    model10  ...  model291  model292  \\\n",
       "0  model1209  model1209  model1209  model1209  ...  model788  model788   \n",
       "1        200        200        200        200  ...       100       100   \n",
       "2        100        100        100        100  ...       100       100   \n",
       "3          3          3          3          3  ...         3         3   \n",
       "4       relu       relu       relu       relu  ...      relu      relu   \n",
       "\n",
       "   model293  model294  model295  model296  model297  model298  model299  \\\n",
       "0  model788  model788  model788  model788  model788  model788  model788   \n",
       "1       100       100       100       100       100       100       100   \n",
       "2       100       100       100       100       100       100       100   \n",
       "3         3         3         3         3         3         3         3   \n",
       "4      relu      relu      relu      relu      relu      relu      relu   \n",
       "\n",
       "   model300  \n",
       "0  model788  \n",
       "1       100  \n",
       "2       100  \n",
       "3         3  \n",
       "4      relu  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.DataFrame(models)\n",
    "df_models.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.to_csv('../output/data/RNA/NN_RawModels_Notebooks6c_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>epochs</th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>regularization</th>\n",
       "      <th>random_state_trainsplit</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>ia_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>ia_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>model1209</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872036</td>\n",
       "      <td>84.137671</td>\n",
       "      <td>6.142833</td>\n",
       "      <td>9.172659</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.770278</td>\n",
       "      <td>154.232328</td>\n",
       "      <td>8.025615</td>\n",
       "      <td>12.419031</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>model1209</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86082</td>\n",
       "      <td>89.543812</td>\n",
       "      <td>6.302811</td>\n",
       "      <td>9.462759</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.778719</td>\n",
       "      <td>161.08846</td>\n",
       "      <td>8.000407</td>\n",
       "      <td>12.692063</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>model1209</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876833</td>\n",
       "      <td>81.290216</td>\n",
       "      <td>6.125698</td>\n",
       "      <td>9.016109</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.751454</td>\n",
       "      <td>164.426907</td>\n",
       "      <td>7.964257</td>\n",
       "      <td>12.822906</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>model1209</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>87.738725</td>\n",
       "      <td>6.265878</td>\n",
       "      <td>9.366895</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.778086</td>\n",
       "      <td>143.987011</td>\n",
       "      <td>7.707175</td>\n",
       "      <td>11.999459</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>model1209</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.870076</td>\n",
       "      <td>85.908342</td>\n",
       "      <td>6.280808</td>\n",
       "      <td>9.268675</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.775326</td>\n",
       "      <td>147.526076</td>\n",
       "      <td>7.878047</td>\n",
       "      <td>12.146031</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_number epochs hidden_neurons hidden_layers activation  \\\n",
       "model1    model1209    200            100             3       relu   \n",
       "model2    model1209    200            100             3       relu   \n",
       "model3    model1209    200            100             3       relu   \n",
       "model4    model1209    200            100             3       relu   \n",
       "model5    model1209    200            100             3       relu   \n",
       "\n",
       "       regularization random_state_trainsplit acc_train  mse_train mae_train  \\\n",
       "model1           0.05                       0  0.872036  84.137671  6.142833   \n",
       "model2           0.05                       2   0.86082  89.543812  6.302811   \n",
       "model3           0.05                       4  0.876833  81.290216  6.125698   \n",
       "model4           0.05                       6    0.8677  87.738725  6.265878   \n",
       "model5           0.05                       8  0.870076  85.908342  6.280808   \n",
       "\n",
       "       rmse_train ia_train  acc_test    mse_test  mae_test  rmse_test ia_test  \n",
       "model1   9.172659    0.965  0.770278  154.232328  8.025615  12.419031   0.934  \n",
       "model2   9.462759    0.962  0.778719   161.08846  8.000407  12.692063   0.937  \n",
       "model3   9.016109    0.966  0.751454  164.426907  7.964257  12.822906   0.928  \n",
       "model4   9.366895    0.963  0.778086  143.987011  7.707175  11.999459   0.936  \n",
       "model5   9.268675    0.964  0.775326  147.526076  7.878047  12.146031   0.937  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = df_models.transpose()\n",
    "df_models = df_models.rename(columns={0:'model_number', 1:'epochs',2:'hidden_neurons',3:'hidden_layers',4:'activation',\n",
    "                        5:'regularization',6:'random_state_trainsplit', 7:'acc_train',8:'mse_train',9:'mae_train',\n",
    "                        10:'rmse_train',11:'ia_train',12:'acc_test',\n",
    "                         13:'mse_test',14:'mae_test',15:'rmse_test',16:'ia_test'})\n",
    "print(df_models.shape)\n",
    "df_models.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.to_csv('../output/data/RNA/NN_ModelsNotebook6c_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model1254'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_model = df_models.loc[df_models.index=='model59','model_number']\n",
    "prev_model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models = pd.DataFrame(columns=['model','6b_model','variable','result'])\n",
    "\n",
    "min_cols = ['mse_train','mae_train','rmse_train',\n",
    "       'mse_test','mae_test','rmse_test']\n",
    "max_cols = ['acc_train','ia_train',\n",
    "            'acc_test','ia_test']\n",
    "\n",
    "i = 0\n",
    "for c in min_cols:\n",
    "    val = df_models[c].min()\n",
    "    df_tmp = df_models.loc[df_models[c]==val].copy()\n",
    "    df_tmp[['epochs']] = df_tmp[['epochs']]/200\n",
    "    df_tmp[['hidden_neurons']] = df_tmp[['hidden_neurons']]/100\n",
    "    df_tmp[['hidden_layers']] = df_tmp[['hidden_layers']]/10\n",
    "    df_tmp[['regularization']] = df_tmp[['regularization']]/1\n",
    "    model = df_tmp[['epochs','hidden_neurons',\n",
    "                    'hidden_layers','regularization']].sum(axis=1).idxmin()\n",
    "    prev_model = df_tmp.loc[df_tmp.index==model,'model_number']\n",
    "    df_best_models.loc[i] = [model, prev_model[0], c, val]\n",
    "    i += 1\n",
    "    \n",
    "for c in max_cols:\n",
    "    val = df_models[c].max()\n",
    "    df_tmp = df_models.loc[df_models[c]==val].copy()\n",
    "    df_tmp[['epochs']] = df_tmp[['epochs']]/200\n",
    "    df_tmp[['hidden_neurons']] = df_tmp[['hidden_neurons']]/100\n",
    "    df_tmp[['hidden_layers']] = df_tmp[['hidden_layers']]/10\n",
    "    df_tmp[['regularization']] = df_tmp[['regularization']]/1\n",
    "    model = df_tmp[['epochs','hidden_neurons',\n",
    "                    'hidden_layers','regularization']].sum(axis=1).idxmin()\n",
    "    prev_model = df_tmp.loc[df_tmp.index==model,'model_number']\n",
    "    df_best_models.loc[i] = [model, prev_model[0], c, val]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>6b_model</th>\n",
       "      <th>variable</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model59</td>\n",
       "      <td>model1254</td>\n",
       "      <td>mse_train</td>\n",
       "      <td>69.556236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model59</td>\n",
       "      <td>model1254</td>\n",
       "      <td>mae_train</td>\n",
       "      <td>5.496591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model59</td>\n",
       "      <td>model1254</td>\n",
       "      <td>rmse_train</td>\n",
       "      <td>8.340038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model255</td>\n",
       "      <td>model788</td>\n",
       "      <td>mse_test</td>\n",
       "      <td>126.002045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model111</td>\n",
       "      <td>model732</td>\n",
       "      <td>mae_test</td>\n",
       "      <td>7.347313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model255</td>\n",
       "      <td>model788</td>\n",
       "      <td>rmse_test</td>\n",
       "      <td>11.225063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model59</td>\n",
       "      <td>model1254</td>\n",
       "      <td>acc_train</td>\n",
       "      <td>0.894781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model59</td>\n",
       "      <td>model1254</td>\n",
       "      <td>ia_train</td>\n",
       "      <td>0.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model149</td>\n",
       "      <td>model732</td>\n",
       "      <td>acc_test</td>\n",
       "      <td>0.808412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model255</td>\n",
       "      <td>model788</td>\n",
       "      <td>ia_test</td>\n",
       "      <td>0.947000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model   6b_model    variable      result\n",
       "0   model59  model1254   mse_train   69.556236\n",
       "1   model59  model1254   mae_train    5.496591\n",
       "2   model59  model1254  rmse_train    8.340038\n",
       "3  model255   model788    mse_test  126.002045\n",
       "4  model111   model732    mae_test    7.347313\n",
       "5  model255   model788   rmse_test   11.225063\n",
       "6   model59  model1254   acc_train    0.894781\n",
       "7   model59  model1254    ia_train    0.972000\n",
       "8  model149   model732    acc_test    0.808412\n",
       "9  model255   model788     ia_test    0.947000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_models.to_csv('../output/data/RNA/BestModels_Notebook6c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = ['random_state_trainsplit']\n",
    "\n",
    "for m in model_var:\n",
    "    df_models.groupby([m]).agg(['mean','std']).to_csv(f'../output/data/RNA/{m}_ModelAnalysis_Notebook6c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('geo_env': conda)",
   "language": "python",
   "name": "python38364bitgeoenvconda2cb6af09078d46c89f7c036ca6304ba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
